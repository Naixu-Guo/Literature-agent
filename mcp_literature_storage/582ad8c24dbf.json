{
  "id": "582ad8c24dbf",
  "source": "/var/folders/05/6f0vjthd471ff1qt42rb7nlw0000gn/T/tmpnj8bgkrm.pdf",
  "metadata": {
    "title": "Quantum Learning with Tunable Loss Functions",
    "source_type": "pdf",
    "path": "/var/folders/05/6f0vjthd471ff1qt42rb7nlw0000gn/T/tmpnj8bgkrm.pdf",
    "pages": 26,
    "file_size": 1630832
  },
  "chunks": [
    "Quantum Learning with Tunable Loss Functions\nYixian Qiu, 1, \u2217 Lirand\u00a8 e Pira,1, \u2020 and Patrick Rebentrost 1, 2, \u2021\n1Centre for Quantum Technologies, National University of Singapore, Singapore\n2Department of Computer Science, National University of Singapore, Singapore\n(Dated: September 1, 2025)\nLearning from quantum data presents new challenges to the paradigm of learning from data. This\ntypically entails the use of quantum learning models to learn quantum processes that come with\nenough subtleties to modify the theoretical learning frameworks. This new intersection warrants\nnew frameworks for complexity measures, including those on quantum sample complexity and gen-\neralization bounds. Empirical risk minimization (ERM) serves as the foundational framework for\nevaluating learning models in general. The diversity of learning problems leads to the development of\nadvanced learning strategies such as tilted empirical risk minimization (TERM). Theoretical aspects",
    "advanced learning strategies such as tilted empirical risk minimization (TERM). Theoretical aspects\nof quantum learning under a quantum ERM framework are presented in [PRX Quantum 5, 020367\n(2024)]. In this work, we propose a definition for TERM suitable to be employed when learning\nquantum processes, which gives rise to quantum TERM (QTERM). We show that QTERM can be\nviewed as a competitive alternative to implicit and explicit regularization strategies for quantum\nprocess learning. This work contributes to the existing literature on quantum and classical learning\ntheory threefold. First, we prove QTERM learnability by deriving upper bounds on QTERM\u2019s sam-\nple complexity. Second, we establish new PAC generalization bounds on classical TERM. Third,\nwe present QTERM agnostic learning guarantees for quantum hypothesis selection. These results\ncontribute to the broader literature of complexity bounds on the feasibility of learning quantum",
    "we present QTERM agnostic learning guarantees for quantum hypothesis selection. These results\ncontribute to the broader literature of complexity bounds on the feasibility of learning quantum\nprocesses, as well as methods for improving generalization in quantum learning.\nI. INTRODUCTION\nLearning is the cornerstone of intelligence, shaping how humans make sense of the world and adapt to it. At its core,\nlearning is the art of discerning patterns. Humans learn by drawing connections and building relationships among\nobjects, using intuition and experience. Similarly, learning machines seek to reveal patterns in data, but instead\nof intuition, they rely on mathematical models and algorithms to identify meaningful structures. Learning theory\nformalizes this process, providing a framework to understand how efficiently a model can generalize from limited data\nand determine the fundamental limits of computation in artificial learning systems [1\u20133].",
    "and determine the fundamental limits of computation in artificial learning systems [1\u20133].\nThe two primary components of machine learning are the dataset and the model [4\u20136]. The optimization process\nof learning from data can be summarized as choosing a model that best fits the dataset. Selecting such a model is\na complex and often non-trivial task due to several factors. Firstly, this process is dependent on the diversity and\ncharacteristics of the data, such as its size, dimensionality, and inherent noise, which can significantly influence model\nperformance. Next, different models have varying assumptions and strengths; for example, some may be better for\nlinear relationships while others are designed for more complex, non-linear patterns. This is where regularization\ntechniques, implicit or explicit, come into the picture. Regularization introduces additional constraints or penalties",
    "techniques, implicit or explicit, come into the picture. Regularization introduces additional constraints or penalties\ninto the model training process, which helps prevent overfitting by discouraging overly complex models. Additionally,\nregularization plays an important role in preventing overfitting, handling model complexity, balancing the role of\noutliers and class imbalance \u2014 all issues arising at model or dataset level. A primary objective of regularization is\nto reduce generalization error, which refers to the difference between a model\u2019s performance on training data and its\nability to perform well on test data.\nThe process of finding a model that best fits a dataset is guided by a loss function, which quantifies the discrepancy\nbetween predicted and actual outcomes. A fundamental principle in supervised learning is empirical risk minimization\n(ERM), which trains models by minimizing the average loss on a dataset. While ERM optimizes performance on",
    "(ERM), which trains models by minimizing the average loss on a dataset. While ERM optimizes performance on\ntraining data, it can be refined through advanced learning techniques such as tilted empirical risk minimization\n(TERM) [7, 8]. TERM extends ERM by incorporating a tilted loss function that selectively emphasizes certain\naspects of the dataset, leading to more nuanced and desirable learning outcomes. This approach is inspired by\nexponential tilting, a well-established concept in statistics [9, 10], information theory [11], and applied probability\n[12], where probability distributions are transformed by scaling them with an exponential factor. Recent studies\n\u2217 yixian qiu@u.nus.edu\n\u2020 lpira@nus.edu.sg\n\u2021 cqtfpr@nus.edu.sg\narXiv:2508.21369v1  [quant-ph]  29 Aug 20252\nOutput optimal  s.t. .h* \u02dcR\u03b3(h*) \u2264 min \u02dcR\u03b3(h) + \u03b5\nQuantum Threshold Search\nAccept\nReject\nc = 1,\u22ef,m : hc = {\u03a0(xi)(c)}i\u2208[n]\nCheck if \n\u02dcR\u03b3(h) < \u03b8c + \u03b5\nYesNo\nOptimize \nthresholds \u03b8c\nInput\nAlgorithm\nOutput\n\u20d7x\nClassical",
    "Quantum Threshold Search\nAccept\nReject\nc = 1,\u22ef,m : hc = {\u03a0(xi)(c)}i\u2208[n]\nCheck if \n\u02dcR\u03b3(h) < \u03b8c + \u03b5\nYesNo\nOptimize \nthresholds \u03b8c\nInput\nAlgorithm\nOutput\n\u20d7x\nClassical  \nData Quantum \nstates\n\u2026\n\u2297\n\u2297\n\u03c13\n\u03c12\n\u03c11\n\u201cGentler\u201d Measurement\nTunable loss \u02dcR\u03b3(h)\nFigure 1: Illustration of the learning process with QTERM. The process incorporates three main parts:\nInput: It begins with classical data and the corresponding quantum state representations. Algorithm: It utilizes a\nquantum threshold search shown in Appendix.IX B, which aims to find an optimal hypothesis classhc\u2217 that minimizes\nthe tunable loss \u02dcR\u03b3(h), subject to the constraint \u02dcR\u03b3(h) \u2264 \u03b8c. Output: The optimal hypothesis set is denoted as\nhc\u2217 = {\u03a0(xi)(c\u2217)}i\u2208[n].\n[13] have explored the generalization properties of TERM as a competitive strategy to achieve similar outcomes as\nexplicit regularization (additive changes to the loss function) and implicit regularization (due to stochastic gradient",
    "explicit regularization (additive changes to the loss function) and implicit regularization (due to stochastic gradient\ndescent [14]), by also analyzing its theoretical implications within the broader framework of computational learning\ntheory [1\u20133]. In particular, TERM\u2019s performance can be evaluated using the PAC (probably approximately correct)\nlearning framework [1], which assesses the accuracy of learning algorithms in relation to the amount of data required\nto generalize effectively. More generally, statistical theoretical bounds with respect to regularization techniques are\nexplored in Refs. [15, 16].\nQuantum machine learning [17\u201321] has emerged as a prospective application of quantum computing [22, 23]. Quan-\ntum machine learning algorithms in its most general form take the flavor of learning from quantum data via quantum\nmodels. Quantum models are studied and benchmarked in the near-term model of quantum computation [24] as well",
    "models. Quantum models are studied and benchmarked in the near-term model of quantum computation [24] as well\nas the fault-tolerant one [25]. Near-term models mainly comprise the class of algorithms known as variational quantum\nalgorithms [26, 27], while in the longer-term range ideas based on quantum singular value transform (or QSVT) [28]\nand block-encodings are brought forth [29, 30]. Here, we take a more holistic approach akin to the quantum model\nformulation under consideration, which is a generalized supervised quantum model suitable to various concept classes.\nThe subtleties quantum characteristics add to the process of learning can be summarized on the level of data input\nand output, as well as the model. For learning theory measures, the quantum nature of data introduces challenges in\ndefining generalization and overfitting due to the probabilistic nature of quantum measurements and the limitations",
    "defining generalization and overfitting due to the probabilistic nature of quantum measurements and the limitations\non state distinguishability. Furthermore, measurement constraints, where only partial information about quantum\nstates is accessible, directly affect empirical risk estimation.\nIn this study, we introduce quantum tilted empirical risk minimization (QTERM), which provides a formal foun-\ndation for developing quantum learning within established learning-theoretic frameworks, as depicted in Fig. 1. We\npresent QTERM as a unification of classical TERM and quantum empirical risk minimization (QERM), thereby\nextending ERM in the quantum setting through a generalization of both approaches. While ERM provides a foun-\ndation for model training via average loss minimization and QERM extends this to quantum data. QTERM further\naugments the QERM framework by introducing a tilting hyperparameter over the quantum empirical risk. This",
    "augments the QERM framework by introducing a tilting hyperparameter over the quantum empirical risk. This\ntilt hyperparameter allows selective emphasis on certain quantum samples, thereby refining the learning objective.\nThis mechanism retains classical TERM\u2019s focus-shifting behavior of a given dataset, but now adapted to quantum3\nmeasurement constraints and statistical properties of quantum states. To formalize this idea, we take an analytical\napproach to defining and developing QTERM for learning from quantum data. In our formulation, quantum data is\nrepresented through a collection of quantum projector-value functions, and the QERM framework [31] is extended by\nincorporating a tilted hyperparameter over discrete quantum samples. This formulation offers a precise operational\ninterpretation: QTERM reduces to QERM when the tilting parameter is neutral, and to classical TERM when applied",
    "interpretation: QTERM reduces to QERM when the tilting parameter is neutral, and to classical TERM when applied\nto classical data with deterministic outcomes. Using the definitions of this framework, we derive sample complexity\nbounds, as well as agnostic learning guarantees for QTERM in a finite hypothesis space. Furthermore, constructing an\nexplicit PAC bound for QTERM establishes its theoretical relevance within the quantum PAC framework, while also\nderiving new generalization results for classical TERM under PAC assumptions. These contributions underscore how\nQTERM unifies and extends both classical and quantum learning paradigms within a common theoretical paradigm.\nA. Related Work on Quantum Learning Theory\nSimilar learning techniques have been explored in the context of quantum models. For instance, structural risk\nminimization [32] is applied analytically to two quantum linear classifiers in Ref. [33], highlighting the trade-off between",
    "minimization [32] is applied analytically to two quantum linear classifiers in Ref. [33], highlighting the trade-off between\ntraining accuracy and generalization performance in parameterized quantum circuits. In parallel, ideas on quantum\nlearning for quantum data have been brought forth in Ref. [34], hereby formalizing a definition of quantum ERM\n(QERM). Ref. [35] generalizes the results of Ref. [34] to broader concept classes and a looser version of compatibility.\nAdditionally, Ref. [36] introduces a quantum ERM algorithm that improves sample complexity bounds in the quantum\nsettings through quantum shadows, enabling more efficient empirical loss estimation in quantum classifiers. Moreover,\nRef. [37] addresses the question of complexity bounds from a quantum learning perspective. Arunachalam and de\nWolf\u2019s survey in Ref. [38] analyzes quantum adaptations of classical models such as PAC learning, noting challenges",
    "Wolf\u2019s survey in Ref. [38] analyzes quantum adaptations of classical models such as PAC learning, noting challenges\nsuch as sample complexity and measurement incompatibilities due to the fundamental nature of quantum mechanics\n[39\u201341]. Properties of learning from quantum data have been studied from a generalization point of view as well [42\u201344].\nQuantum PAC is introduced to address the challenges and adaptations required for the PAC framework when applied\nto learning from quantum data [34\u201336, 38, 45, 46]. For instance, in Refs. [34, 36], the quantum PAC framework\naccounts for quantum data which is represented as the density operator over a Hilbert space, and secondly, for\ninformation loss incurred by the measurement process. Quantum sample complexity for the quantum PAC framework\nproposed in Ref. [34] is known to be higher compared to the classical analogue.\nB. Problem Setup and Desiderata",
    "proposed in Ref. [34] is known to be higher compared to the classical analogue.\nB. Problem Setup and Desiderata\nConsider the task of learning an optimal projector-valued hypothesis from classical-quantum distribution where\nquantum states provided in a product-state form. Without loss of generality, assume x1, . . . , xn be i.i.d., classical\nsamples drawn from a continuous distribution with uncountably many possible values. For each sample xi, it is\npractically impossible to obtain identical copies of the corresponding quantum state. Accordingly, we associated a\nsingle copy quantum state \u03c1(xi) to each sample xi. The learner\u2019s joint quantum state is therefore the product state\n\u03c1(\u20d7 x) =\nnO\ni=1\n\u03c1(xi),\nwhere each \u03c1(xi) is available only as a single copy. In particular, there is no way to request \u03c1(xi) \u2297 \u03c1(xi) for any\ni. Consequently, all measurements must be performed on the tensor product of nonidentical, single-copy states, and",
    "i. Consequently, all measurements must be performed on the tensor product of nonidentical, single-copy states, and\nmust be designed \u201cgently\u201d so as not to destroy information needed for subsequent steps. Fix a hypothesis class\nC = {hc : c \u2208 [m]}, where each hc generates a set of corresponding projectors {\u03a0(xi)(c)}n\ni=1. The quality of a\nhypothesis is assessed using a loss function defined via projector-valued operations denoted as Tr[ \u03c1(xi)\u03a0(xi)(c)]. To\nestimate the loss, the learner performs measurements on \u03c1(xi), and these measurements are implemented gently on\n\u03c1(\u20d7 x), so that extracting information about Tr[\u03c1(xi) \u03a0(xi)(c)] does not destroy the samples that are still needed to test\nthe rest of hypotheses. Within this setting, we introduce TERM parameterized by \u03b3 \u2208 R, which provides a way to\ncontrol sensitivity to extreme values, manifested in the form of data irregularities. The tilted risk function is defined\nas:\neR\u03b3(c) = 1 \u2212 1\n\u03b3 log\n \n1\nn\nnX\ni=1\ne\u03b3Tr[\u03c1(xi)\u03a0(xi)(c)]\n!\n. (1)",
    "control sensitivity to extreme values, manifested in the form of data irregularities. The tilted risk function is defined\nas:\neR\u03b3(c) = 1 \u2212 1\n\u03b3 log\n \n1\nn\nnX\ni=1\ne\u03b3Tr[\u03c1(xi)\u03a0(xi)(c)]\n!\n. (1)\nFor proving our learning guarantee, a certain regime of\u03b3 is required. For our concentration bounds to hold, we require\n|\u03b3| < 1, since \u03b3 \u2192 0 recovers the ordinary mean loss and \u03b3 too large overemphasizes outliers. In particular, for \u03b3 \u2192 0,4\nthe tilted risk reduces to the standard case of the mean loss 1 \u2212 Pn\ni=1 Tr[\u03c1(xi)\u03a0(xi)(c)]. The mean loss by default\ndoes not overweight extreme values. As \u03b3 \u2192 +\u221e, eR\u03b3(c) behaves like 1\u2212maxi\u2208[n] Tr[\u03c1(xi)\u03a0(xi)(c)]. Large \u03b3 amplifies\nvariations in the loss landscape, which can be useful for minimizing outliers.\nA more familiar way to interpret the role of \u03b3 is through comparisons with standard norms. For sufficiently small\n\u03b3, the tilted empirical risk behaves similarly to an L1-type averaging, providing a balanced estimate of the loss across",
    "\u03b3, the tilted empirical risk behaves similarly to an L1-type averaging, providing a balanced estimate of the loss across\nsamples. As \u03b3 increases, the risk shifts toward an L2-like behavior, amplifying higher-loss samples and emphasizing\nvariance. In the extreme case of very large \u03b3, the tilted empirical risk resembles a max function (akin to an L\u221e\nnorm), where a few high-loss samples dominate the overall evaluation. See Lemma 4 for a more formal formulation\non the convergence of the tilted hyperparameter.\nC. Main Contributions\nWe address the problem of learning from classical-quantum data by finding an optimal projector-valued hypothesis\nclass. Our main idea is to modify the loss function to be the tilted loss function with a tilted hyperparameter \u03b3.\nFor the quantum problem, we prove a sample complexity result using the tilted loss for intermediate values of the\ntilted hyperparameter \u03b3. In addition, we prove a new PAC generalization bound for the tilted loss minimization for",
    "tilted hyperparameter \u03b3. In addition, we prove a new PAC generalization bound for the tilted loss minimization for\nsufficiently small \u03b3. These two results enable us to prove our third result for a guarantee of agnostic learning for small\nvalues of \u03b3.\nWe list the main contributions of this paper as follows.\n\u2022 Generalization of QERM and formalization of QTERM. This contribution builds upon the QERM frame-\nwork introduced in Ref. [31], by incorporating the tilted hyperparameter to generalize the theoretical framework\nof quantum empirical risk minimization. Hereby, we define and formalize QTERM, extending the concept of\nempirical risk minimization to quantum models trained in quantum states, formally defined in Definition 2.\n\u2022 Learnability of projector-valued functions under sample complexity guarantees . We derive sample\ncomplexity bounds for QTERM, providing theoretical guarantees on the number of quantum state samples",
    "\u2022 Learnability of projector-valued functions under sample complexity guarantees . We derive sample\ncomplexity bounds for QTERM, providing theoretical guarantees on the number of quantum state samples\nrequired to achieve reliable learning performance. These limits provide a deeper understanding of the interaction\nbetween the tilted hyperparameter, the complexity of the model, and the data requirements, expressed in\nTheorem 1, and more formally in Theorem 7. We state an informal version of the main theorem in Theorem 1.\nThe main theorem answers the following question.\n\u2013 How can we efficiently identify the best hypothesis (i.e., a set of projectors) that describes a given quantum\nsystem?\n\u2013 How many quantum samples (product states) are needed to guarantee a reliable choice?\nTheorem 1 (Quantum Tilted Empirical Risk for Projector-Valued Functions, informal) . For quantum process\nlearning with product states, our objective is to identify the best hypothesis among m projector-valued functions",
    "learning with product states, our objective is to identify the best hypothesis among m projector-valued functions\nusing tilted empirical risk, a modified risk function controlled by the tilted hyperparameter \u03b3. With enough\nquantum samples (approximately 1\n\u03b52 log 1\n\u03b4 log2 1\n\u03b5 , plus factors depending on \u03b3 and m), an algorithm can reliably\nestimate the best hypothesis. Guarantees that the estimated risk is within \u03b5 of the true minimum with a failure\nprobability of at most \u03b4.\n\u2022 Generalization bound for TERM. When the tilted loss class has a controlled covering number and the\ntilted hyperparameter \u03b3 is sufficiently small, the tilted empirical risk reliably tracks the true population risk\nwith certain samples; the risk gap stays below \u03b5 with probability at least 1 \u2212\u03b4. In short, this theorem addresses\nthe following questions.\n\u2013 How well does the tilted empirical risk approximate the true risk?\nTheorem 2 (PAC Bound of TERM, informal) . Suppose we minimize TERM over a set of functions. If the",
    "the following questions.\n\u2013 How well does the tilted empirical risk approximate the true risk?\nTheorem 2 (PAC Bound of TERM, informal) . Suppose we minimize TERM over a set of functions. If the\nfunction class has a small enough uniform covering number and the tilted hyperparameter \u03b3 is sufficiently small,\nthen, with high probability over random samples, the tilted empirical risk is close to the true population risk.\nThe probability of a large deviation decays exponentially in the number of samples n.\n\u2022 Agnostic learning guarantees for quantum hypothesis selection. We establish agnostic learning bounds\nfor QTERM, extending the theoretical framework to settings where the true hypothesis may not belong to the\ngiven class. This result ensures that even in the absence of a perfect hypothesis, we can still approximate the5\nInput: Hypothesis class ; a set of projector-\nvalued functions ; threshold ; \n; loss function ; tilt .\nOutput: The estimated value of",
    "Goal: To learn concept classes of in\ufb01nite cardinality with \n\ufb01nite amount of samples, output hypothesis  for  \nsuch that  \nC = {hc}c\u2208[m]\nhc = {\u03a0(xi)(c)}i\u2208[n] \u03b8c\n\u03c1 = \u2297n\ni=1 \u03c1i Tr[\u03c1i\u03a0(xi)(c)] \u03b3 \u2208 (0,\u03b5)\n\u02dcR\u03b3(h) = 1 \u2212 1\n\u03b3 log (\n1\nn\nn\n\u2211i=1\ne\u03b3Tr[\u03c1i\u03a0(xi)(c)]\n) \u2264 \u03b8c\nhc* \u03b5 > 0\n\u02dcRest\n\u03b3 (h*) \u2264 minh\u2208C\n\u02dcR\u03b3(h) + \u03b5\nTERM FOR PROJECTOR-VALUED FUNCTIONS (QTERM)\nTILTED EMPIRICAL RISK MINIMIZATION (TERM)\nTHEOREM 3: LEARNABILITY\nThere is an agnostic algorithm outputs  with small \nprobability whose true error is within \u03b5 of the best possible, \nif assume that .\nc*\nlimn\u2192\u221e\nlog2 \u03931,\u221e(n, \u03b5, C)\nn = 0, \u2200\u03b5 > 0\nTHEOREM 1: SAMPLE COMPLEXITY\nThere exists an algorithm to reach accuracy  with con\ufb01dence \n that outputs  with sample complexity , \nwhere  suppresses polylogarithmic factors of .\n\u03b5\n1 \u2212 \u03b4 c* \u02dcO (2|\u03b3|\u03b5\u22122 log m)\n\u02dcO( \u22c5 ) 1/\u03b5, 1/\u03b4\nTHEOREM 2: PAC GENERALIZATION BOUND\nWe obtain that ,  with \nprobability depending on the covering number.\n\u2203h \u2208 \u2131 : R(h) \u2212 \u02dcR\u03b3(h) \u2264 \u03b5\nClassical\nFor , , given any  and Hamiltonian ,",
    "\u02dcO( \u22c5 ) 1/\u03b5, 1/\u03b4\nTHEOREM 2: PAC GENERALIZATION BOUND\nWe obtain that ,  with \nprobability depending on the covering number.\n\u2203h \u2208 \u2131 : R(h) \u2212 \u02dcR\u03b3(h) \u2264 \u03b5\nClassical\nFor , , given any  and Hamiltonian , \nthe -tilted QTR is .\n\u03d5 \u2208 \u03a6 \u03b3 \u2208 \u211d \u03c1 H(\u03d5)\n\u03b3 \u02dcRQ(\u03b3, \u03d5) := 1\n\u03b3 log Tr(e\u03b3H(\u03d5)\u03c1)\nDEFINITION: QUANTUM TILTED RISK (QTR)\nQuantum\nType of Hypothesis\nType of Data\nCQ QQ\nQCCC\nC\nQ\nFigure 2: Overview of the learning framework and main theoretical results. This diagram provides a\ncomprehensive overview of our QTERM framework for learning quantum processes. The left side outlines the key\nalgorithm: which takes as input a hypothesis class, projector-valued functions, product states and corresponding loss\nfunction, and a tilting parameter. Through quantum threshold search, the algorithm outputs an optimal hypothesis\nh\u2217 that minimizes risk. On the right, the figure contextualizes our work by showing how our work extends across",
    "h\u2217 that minimizes risk. On the right, the figure contextualizes our work by showing how our work extends across\ndifferent types of data and different types of hypotheses (classical and quantum). Our key theoretical contributions,\nincluding provable guarantees on sample complexity, PAC generalization, and agnostic learnability, are summarized\nby Theorems 1-3, while simultaneously introducing the novel concept of quantum tilt risk (QTR).\nbest achievable performance within a controlled error margin. Our guarantees are formalized in Theorem 10,\nand an informal version is given in Theorem 3.\nThe follow-up theorem establishes agnostic learning guarantees for the quantum setting, removing the assump-\ntion that an optimal hypothesis exists within the given hypothesis class. In particular, this theorem answers\nthe following question.\n\u2013 How well can we approximate the best possible hypothesis when no perfect hypothesis exists?",
    "the following question.\n\u2013 How well can we approximate the best possible hypothesis when no perfect hypothesis exists?\nTheorem 3 (Agnostic Learnability of Projector-Valued Function, informal) . If a class of projector-valued\nfunctions C is not too complex, in the sense that its covering numbers grow slowly with the number of samples,\nthen there exists an algorithm that, given enough training data drawn from an unknown classical-quantum\nchannel, can find a hypothesis c\u2217 \u2208 Cwhose performance is close to optimal and whose estimated performance\nis close to the true value. Moreover, the probability of making a significant error can be made arbitrarily small\nby choosing the sample size appropriately, depending on the desired accuracy, confidence, and the complexity of\nC.\nIt is worth highlighting that the theoretical guarantees hold for a certain threshold value of \u03b3. Throughout our",
    "C.\nIt is worth highlighting that the theoretical guarantees hold for a certain threshold value of \u03b3. Throughout our\nanalysis we observe that the learning becomes significantly more difficult for large \u03b3 values. From a perspective of\nsample complexity, the bounds we establish in this work hold primarily for sufficiently small \u03b3. A lesson from our\nlearning guarantee for the generalization error is the exponential dependence on \u03b3 which could make reliable learning\nfor large \u03b3 difficult. A contextualization of our contributions is illustrated in Fig. 2.\nD. Outline of this Work\nThis paper is structured as follows. Section II lays the theoretical foundations of the learning model under con-\nsideration, empirical risk minimization, the TERM paradigm, and their quantum extensions to QERM. Section III6\nintroduces the formal definition of QTERM and derives sample complexity bounds for learning quantum processes.",
    "introduces the formal definition of QTERM and derives sample complexity bounds for learning quantum processes.\nSection IV presents new measures of PAC generalization bounds on classical TERM. Section V introduces learning\nguarantees under the consideration of agnostic learning. Section VI introduces further ideas on defining tilted mea-\nsures for quantum systems potentially related to Hamiltonian learning. We also comment on the necessity of the\ndifferent methods of defining the tilt mechanism in different quantum learning settings and applications. This study\nconcludes in Section VII with a summary of its contributions and an outlook on open directions. Some of the proofs\nand details on algorithms are deferred to Section IX A and Section IX B, respectively.\nII. THEORETICAL FOUNDATIONS\nA. Learning Model Formulation\nThere exist multiple model formulations within the learning theoretical frameworks. The well-known PAC learning",
    "II. THEORETICAL FOUNDATIONS\nA. Learning Model Formulation\nThere exist multiple model formulations within the learning theoretical frameworks. The well-known PAC learning\nin the quantum setting is a framework for studying quantum machine learning algorithms, extending the classical\nPAC learning model to quantum settings. In this framework, the goal is for a learner to approximately learn a target\nquantum state or quantum process from a finite number of quantum samples, with high probability and within a\nspecified accuracy. Quantum PAC learning has been formalized in multiple settings.\nA supervised quantum machine learning model M is defined as:\nM = (H, U(\u03b8), E, M, L), (2)\nwhere H is a complex Hilbert space representing the state space, U(\u03b8) is a parameterized unitary operator acting on\nH, transforming quantum states. The function E : Rd \u2192 His an encoding function mapping classical inputs x to",
    "H, transforming quantum states. The function E : Rd \u2192 His an encoding function mapping classical inputs x to\nquantum states |\u03d5\u27e9, M : H \u2192 Yis a measurement operator that extracts classical predictions \u02c6 y from the quantum\nstate, L : Y \u00d7 Y \u2192R is a loss function measuring the difference between true labels y and predicted labels \u02c6y. The\nmodel aims to minimize the expected loss:\nL(\u03b8) = 1\nN\nNX\ni=1\nL(yi, M(U(\u03b8)E(xi))), (3)\nover a training dataset D = {(xi, yi)}N\ni=1.\nAgnostic learning generalizes PAC learning by removing the assumption that the target function is contained within\nthe hypothesis class. Formally, given a hypothesis class H and a distribution D over the input space X, the objective\nin agnostic learning is to find a hypothesis h \u2208 Hthat minimizes the expected loss over D, i.e.,\ninf\nh\u2208H\nE(x,y)\u223cD[L(y, h(x))]. (4)\nUnlike the PAC setting, where a realizable assumption ensures that there exists a hypothesis with zero or arbitrarily",
    "inf\nh\u2208H\nE(x,y)\u223cD[L(y, h(x))]. (4)\nUnlike the PAC setting, where a realizable assumption ensures that there exists a hypothesis with zero or arbitrarily\nlow error, the agnostic framework considers the worst-case scenario where the best hypothesis in H may still incur\nsignificant error. In the quantum setting, this distinction is particularly relevant when learning quantum processes, as\nthe true quantum process may not be exactly representable within the chosen hypothesis class. As shown in Ref. [31],\nwhen access to training data is constrained by quantum measurement limitations, the agnostic framework provides\na formulation for bounding sample complexity, ensuring that learning guarantees remain valid even when the true\nquantum process deviates from the assumed model class.\nB. Tilted Empirical Risk Minimization (TERM)\nEmpirical risk minimization is widely used in machine learning where the goal is to optimize model parameters by",
    "B. Tilted Empirical Risk Minimization (TERM)\nEmpirical risk minimization is widely used in machine learning where the goal is to optimize model parameters by\nminimizing the average loss over the training data [47]. The key idea behind ERM is that, because we do not know\nthe true distribution that generated the data, we use the available training data to estimate the risk by averaging the\nloss over the dataset. However, ERM has notable limitations, particularly when dealing with outliers or imbalanced\ndata, and generalizing to unseen data. For example, in situations where certain data subgroups are underrepresented\nor contain outliers, the model may overfit to noisy data or produce unfair solutions, especially if the outliers belong\nto subgroups that we aim to serve better. To mitigate some of the challenges of ERM, an idea is to use tilted losses\nas a generalization of this traditional technique. Motivated in large by exponential tilting in deviation theory, works",
    "as a generalization of this traditional technique. Motivated in large by exponential tilting in deviation theory, works\nin Refs. [7, 8] introduce TERM, an extension of ERM with an additional tilted hyperparameter \u03b3. The flexibility7\nof tilted hyperparameter allows the model to continuously adjust decision boundaries based on the problem settings,\noffering robustness against outliers, fairness towards underrepresented subgroups, or a balance between both. This\napproach is especially useful in classification tasks where different groups or data distributions require varying levels\nof emphasis. Tilted empirical risk bears resemblance with the LogExpSum function, adjusting focus or smoothing\nbehavior through log-exp functions.\nThe setting of supervised learning can be defined as follows. Let D = {(x1, y1), (x2, y2), . . . ,(xn, yn)} denote a\ntraining set, where xi \u2208 Xrepresents the input feature vector and yi \u2208 Ydenotes the corresponding output label for",
    "training set, where xi \u2208 Xrepresents the input feature vector and yi \u2208 Ydenotes the corresponding output label for\neach instance i \u2208 {1, 2, . . . , n}. The objective of supervised learning is to learn a mapping function f : X \u2192 Ythat\nminimizes the expected prediction error on the output space. This is typically achieved by optimizing a loss function\nL(yi, \u02c6yi), where \u02c6yi = f(xi) is the predicted label for the input xi. The optimization process can be expressed as:\n\u02c6f = arg min\nf\u2208F\n1\nn\nnX\ni=1\nL(yi, f(xi)), (5)\nwhere F denotes the hypothesis space of possible functions. The trained model \u02c6f is then expected to generalize\nto unseen data, allowing for accurate predictions on new instances x \u2208 X. Generalization error quantifies how\nwell the learned model \u02c6f performs on new samples drawn from the same data distribution D as the training data.\nGeneralization error E can be expressed as:\nE(x,y)\u223cD [L(y, \u02c6y)] \u2212 1\nn\nnX\ni=1\nL(yi, \u02c6yi), (6)",
    "Generalization error E can be expressed as:\nE(x,y)\u223cD [L(y, \u02c6y)] \u2212 1\nn\nnX\ni=1\nL(yi, \u02c6yi), (6)\nwhere L(y, \u02c6y) is the loss function measuring the difference between the true label y and the predicted label \u02c6y = \u02c6f(x).\nMinimizing generalization error is the primary goal of a supervised learner. Following the above, we can now define\nERM more formally.\nDefinition 1 (Empirical Risk Minimization \u2014 ERM [47]). For a hypothesis h(x(i)), empirical risk minimization, the\naverage loss over the training data, is defined as\n\u00afR(\u03b8) := 1\nN\nX\ni\u2208[N]\nL(h(x(i)), y(i), \u03b8), (7)\nwhere L(h(xi), yi, \u03b8) is the loss function that quantifies the distance between the prediction h(xi) and true label yi\nand parameter \u03b8, N is the number of training data points.\nThe performance of ERM is influenced by sample complexity, which refers to the number of samples required to\nachieve a certain level of generalization error. In order to establish good generalization performance, it is important to",
    "achieve a certain level of generalization error. In order to establish good generalization performance, it is important to\nunderstand the relationship between the complexity of the hypothesis space and the amount of training data. While\nERM focuses on minimizing the average loss over the training dataset, TERM introduces a modified approach by\napplying the exponential tilting technique to ERM, assigning different level of emphasis to the loss of samples. TERM\ncan be defined as below.\nDefinition 2 (Tilted Empirical Risk Minimization \u2014 TERM [7, 8]). For \u03b3 \u2208 R \\0, the \u03b3-tilted loss in ERM is defined\nas the tilted empirical risk minimization, given by\neR\u03b3(h) := 1\n\u03b3 log\n\uf8eb\n\uf8ed 1\nN\nX\ni\u2208[N]\ne\u03b3L(h(x(i)),yi,\u03b8)\n\uf8f6\n\uf8f8, (8)\nwhere L(h(x(i)), yi, \u03b8) is the loss function on hypothesis h(x(i)), true label yi and parameter \u03b8, and N is the number\nof training samples.\nThe TERM framework introduces a flexible tilting tool to address the shortcomings of ERM, offering more robust",
    "of training samples.\nThe TERM framework introduces a flexible tilting tool to address the shortcomings of ERM, offering more robust\nsolutions by adjusting the sensitivity of model to outliers using the tilted hyperparameter. Solutions such as TERM are\ncrucial to complementing ERM, because of its sensitivity to overfitting. TERM, in turn, ensures lower generalization\nerror. The generalization error of QTERM for both bounded and unbounded loss functions has been studied with\nrespect to both information-theoretic as well as uniform bounds [13]. Across both bounded and unbounded loss\nfunctions, the convergence rates for the upper bounds consistently exhibit a rate of O(1/\u221an), where n is the number\nof training samples.8\nC. Mathematical Framework and Assumptions\nIn classical learning, the effectiveness of TERM relies on specific conditions related to the complexity of the hypoth-",
    "of training samples.8\nC. Mathematical Framework and Assumptions\nIn classical learning, the effectiveness of TERM relies on specific conditions related to the complexity of the hypoth-\nesis class. A key tool we use to analyze this complexity is the covering number, a standard measure of the effective\nsize of a concept class formalized by Ref. [48].\nDefinition 3 (Covering Number). Let G \u2286L(H)X be a class of functions mapping from a space X to bounded linear\noperators on a Hilbert space H, and let \u03b5 \u2208 (0, 1]. The covering number of G is defined as:\n\u03931,q(n, \u03b5,G) := max {Nin(\u03b5, G, \u2225 \u00b7 \u22251,q,\u00afx) | \u00afx \u2208 Xn}, (9)\nwhere Nin(\u03b5, G, d) is the minimal cardinality of any internal \u03b5-cover of G under the pseudometric d, given by the\nseminorm \u2225 \u00b7 \u22251,q,\u00afx and \u00afx = (x1, . . . , xn) \u2208 Xn a sample of size n.\nTo treat concept classes whose hypotheses take values in an operator algebra rather than in R, we introduce an",
    "seminorm \u2225 \u00b7 \u22251,q,\u00afx and \u00afx = (x1, . . . , xn) \u2208 Xn a sample of size n.\nTo treat concept classes whose hypotheses take values in an operator algebra rather than in R, we introduce an\noperator-class covering number, defined with a seminorm specifically tailored to operator-valued functions:\nDefinition 4 (Operator-class covering number) . Let C \u2286 L(H)X be a hypothesis class, and let \u2225 \u00b7 \u2225p,q,\u20d7 xdenote\na seminorm over datasets \u20d7 x\u2208 Xn. Given \u03b5 > 0, the operator-class covering number \u0393 p,q(n, \u03b5,C) quantifies the\ncomplexity of C, defined as the minimal cardinality of an internal \u03b5-cover.\nDefinition 5 (Exponentially tilted loss-function class). Let F \u2286Y X be any function class and let L : Y \u00d7Y \u2192 [0, a]\nbe a bounded loss. For any tilting parameter \u03b3 >0 we define the \u201cexponential loss-function class\u201d associated with\n(F, L, \u03b3) by\nGF,L,\u03b3 = {gh : X \u00d7Y \u2192 [1, e\u03b3a] |h \u2208 F, gh(x, y) = exp(\u03b3 L(y, h(x)))}.",
    "be a bounded loss. For any tilting parameter \u03b3 >0 we define the \u201cexponential loss-function class\u201d associated with\n(F, L, \u03b3) by\nGF,L,\u03b3 = {gh : X \u00d7Y \u2192 [1, e\u03b3a] |h \u2208 F, gh(x, y) = exp(\u03b3 L(y, h(x)))}.\nThis mirrors the structure of the induced loss-function class in Definition 6 in [31] while replacing the original loss\nwith the exponential tilting loss. The authors establish a quantum variant of ERM for projector-value concept class\nas below, which is the basis of our result for extension to quantum variant of tilted ERM.\nFact 1 (Quantum empirical risk minimization (QERM) for projector-valued functions, Theorem 1 in [31]) . Let us\nconsider a product state \u03c1 = \u03c11 \u2297 \u00b7\u00b7\u00b7 \u2297\u03c1n and a collection of projectors {\u03a0(c)\n1 , . . . ,\u03a0(c)\nn }m\nc=1, where\n\u00b5c = 1\nn\nnX\ni=1\nTr[\u03c1i\u03a0(c)\ni ].1\nThere exists an algorithm that outputs both an index c\u2217 and an estimated value \u02c6\u00b5c\u2217 such that\nPr\n\u0012\f\f\f\f\u02c6\u00b5c\u2217 \u2212 max\nc\u2208[m]\n\u00b5c\n\f\f\f\f \u2265 \u03b5 \u222a |\u02c6\u00b5c\u2217 \u2212 \u00b5c\u2217| \u2265\u03b5\n\u0013\n\u2264 \u03b4,",
    "c=1, where\n\u00b5c = 1\nn\nnX\ni=1\nTr[\u03c1i\u03a0(c)\ni ].1\nThere exists an algorithm that outputs both an index c\u2217 and an estimated value \u02c6\u00b5c\u2217 such that\nPr\n\u0012\f\f\f\f\u02c6\u00b5c\u2217 \u2212 max\nc\u2208[m]\n\u00b5c\n\f\f\f\f \u2265 \u03b5 \u222a |\u02c6\u00b5c\u2217 \u2212 \u00b5c\u2217| \u2265\u03b5\n\u0013\n\u2264 \u03b4,\nif the number of samples n is sufficiently large. Specifically, n can be chosen as\nn = O\n \nlog 1\n\u03b4 max\n\u0000\nlog m\n\u03b4 , log2(em)\n\u0001\n\u03b52\n!\n.\nThe next lemma summarise a key property of the TERM framework.\nLemma 4 (Convergence of eR\u03b3(\u03b8), Lemma 4 in [7, 8]) . Consider that the loss function L(xi; \u03b8) belongs to the differ-\nentiability class C1 (i.e., continuously differentiable) with respect to \u03b8 \u2208 \u0398 \u2286 Rd for i \u2208 [N]. Tilted empirical risk\neR\u03b3(\u03b8) converges to min-loss, ERM, max-loss as t moves from \u2212\u221e to \u221e.\nHence, noted that the parameter \u03b3 controls the focus of the risk function as tilting hyperparameter varies.\n1 For simplicity, we will subsequently denote \u03c1(xi) as \u03c1i, \u03a0(xi) as \u03a0i.9\nD. Quantum Threshold Search",
    "1 For simplicity, we will subsequently denote \u03c1(xi) as \u03c1i, \u03a0(xi) as \u03a0i.9\nD. Quantum Threshold Search\nQuantum threshold search proposed in Ref.[31] operates on a product state of non-identical quantum states, a\ncrucial generalization from prior work [49] that required identical copies. This algorithm enables learning from\nclassical-quantum data in practical scenarios where input cannot be controlled. It\u2019s mainly designed to solve a\nspecific learning problem: given an unknown quantum state, the goal is to find an \u2018observable-threshold\u2019 pair from\na predefined set where the expectation value of observable exceeds that threshold on the state. Its properties are\ndefined in Lemma 5.\nLemma 5 (Quantum threshold search on nonidentical states, Lemma 1 in [31]) . Suppose that given the following\ninputs:\n(a) A single product state \u03c1 = \u03c11 \u2297 \u00b7\u00b7\u00b7 \u2297\u03c1n \u2208 D(H(d))\u2297n, with each \u03c1i a (possibly nonidentical) qudit state.\n(b) Parameters \u03b5 \u2208 [0, 1].\n(c) A collection of lists of projectors {\u03a0(c)",
    "inputs:\n(a) A single product state \u03c1 = \u03c11 \u2297 \u00b7\u00b7\u00b7 \u2297\u03c1n \u2208 D(H(d))\u2297n, with each \u03c1i a (possibly nonidentical) qudit state.\n(b) Parameters \u03b5 \u2208 [0, 1].\n(c) A collection of lists of projectors {\u03a0(c)\n1 , . . . ,\u03a0(c)\nn }c\u2208[m].\n(d) A set of known thresholds {\u03b8c}c\u2208[m] where \u03b8c \u2208 [0, 1].\nAssume there is at least one c for which\n1\nn\nnX\ni=1\nTr\nh\n\u03a0(c)\ni \u03c1i\ni\n> \u03b8c.\nThen there exists an algorithm such that\n(a) Performs a two-outcome measurement {Bc, 1 \u2212 Bc} at each step c = 1 , . . . , m, based on the projectorsn\n\u03a0(c)\n1 , . . . ,\u03a0(c)\nn\no\n.\n(b) If the measurement accepts Bc, then the algorithm halts and outputs c, otherwise it proceeds to c + 1.\nIf the condition holds: (log m + C2)2 < C1n\u03b52 for appropriate constants C1, C2 > 0, it outputs c such that\n1\nn\nnX\ni=1\nTr\nh\n\u03a0(c)\ni \u03c1i\ni\n\u2265 \u03b8c \u2212 \u03b5\nwith probability at least 0.03.\nThe quantum threshold search algorithm is formulated as Algorithm 1 in Sec. IX B. This algorithm runs a sequence",
    "1\nn\nnX\ni=1\nTr\nh\n\u03a0(c)\ni \u03c1i\ni\n\u2265 \u03b8c \u2212 \u03b5\nwith probability at least 0.03.\nThe quantum threshold search algorithm is formulated as Algorithm 1 in Sec. IX B. This algorithm runs a sequence\nof two-outcome POVMs Bc on the same state, halting as soon as it finds a projector list whose sample average exceeds\nits threshold, or else certifying that none do.\nThis technique leverages a generalization of standard measurement, the gentler technique from Refs. [31, 49] to\nachieve improved performance. Unlike standard projective measurements, which can cause significant state collapse,\ngentle measurements allow us to check if an expectation value is above or below a threshold without fundamentally\naltering the quantum state. This is crucial for our setting, which involves products of non-identical states. We then\noptimize the threshold for each concept using binary search. Specifically, we begin with a candidate threshold of 1/2.",
    "optimize the threshold for each concept using binary search. Specifically, we begin with a candidate threshold of 1/2.\nFor each iteration, we run Algorithm 1 on a new batch of data to check if a candidate below the current threshold\nexists. Based on this result, we select either the lower or upper half of the candidate interval, updating the threshold\nto 1/4 or 3/4, respectively. This process continues until we approximate the empirical risk to a desired precision.\nThe next section makes use of the lemmas and propositions defined above, in order to define and formalize TERM\nin the presence of quantum states.\nIII. TILTED EMPIRICAL RISK FOR QUANTUM LEARNING (QTERM)\nIn this section, we introduce a TERM version tailored for quantum learning problem which we refer to as QTERM\nfrom quantum TERM. Specifically, this framework focuses on learning from quantum data by using collections of",
    "from quantum TERM. Specifically, this framework focuses on learning from quantum data by using collections of\nprojector-valued hypotheses. We define a tunable loss function based on the probability of not accepting these\nprojector-valued functions with a tilting parameter.10\nDefinition 6 (Tilted Empirical Risk Minimization for Projector-Valued Functions). Let m hypotheses be represented\nby projector-valued functions hc,s = {\u03a0(c)\ns,1, . . . ,\u03a0(c)\ns,l }, where s indexes blocks of size l. Given a product state \u03c1 =\n\u03c11 \u2297 \u00b7\u00b7\u00b7 \u2297\u03c1n, with \u03c1s \u2208 D(H(d)), the tilted empirical risk of hypothesis c for tilting parameter \u03b3 \u2208 R is:\neR\u03b3(h) := 1 \u2212 1\n\u03b3 log\n \n1\nn\nnX\ni=1\ne\u03b3Tr[\u03c1i\u03a0(c)\ni ]\n!\n. (10)\nThis definition provides the theoretical foundation for our QTERM framework, enabling us to identify an optimal\nhypothesis that approximately minimizes the true tilted risk R(h) with tunable losses.\nWe will adopt this method to implement TERM within our framework. Its properties are defined in the following",
    "hypothesis that approximately minimizes the true tilted risk R(h) with tunable losses.\nWe will adopt this method to implement TERM within our framework. Its properties are defined in the following\nproposition. It is primarily adapted from Lemma 2 and Lemma 5 in [31], with necessary adjustments made\u2014mainly\nreplacing the empirical risk with the tilted empirical risk.\nProposition 6 (Conditions on QTERM given sufficiently large product states) . Given product states divided into\nn/l = 2 T kblocks as \u03c1 = \u03c11 \u2297 \u00b7\u00b7\u00b7 \u2297\u03c12Tk , where\u03c1s = \u03c1s,1 \u2297 \u00b7\u00b7\u00b7 \u2297\u03c1s,l, and a collection of lists of projectors\n{\u03a0(c)\ns,1, . . . ,\u03a0(c)\ns,l }c\u2208[m], s\u2208[2Tk ], assume that the following conditions hold:\n(i) For proper constants C1, C2 > 0, let\nl >(log m + C2)2\nC1\u03b52 . (11)\n(ii) Simultaneously,\nl >log(T k/\u03b4)\n\u03b52 (12)\nfor large enough T = O(log 1\n\u03b5 ) and k = O(log 1\n\u03b4 log 1\n\u03b5 ).\n(iii) The tilted empirical risk of each hypothesis c for \u03b3 is defined as\neR\u03b3(c) = 1 \u2212 \u00b5c(\u03b3) := 1 \u2212 1\n\u03b3 log\n\uf8eb\n\uf8ed1\nl\nlX\nj=1\ne\u03b3Tr[\u03c1s,j\u03a0(c)\ns,j]\n\uf8f6",
    "\u03b5 ) and k = O(log 1\n\u03b4 log 1\n\u03b5 ).\n(iii) The tilted empirical risk of each hypothesis c for \u03b3 is defined as\neR\u03b3(c) = 1 \u2212 \u00b5c(\u03b3) := 1 \u2212 1\n\u03b3 log\n\uf8eb\n\uf8ed1\nl\nlX\nj=1\ne\u03b3Tr[\u03c1s,j\u03a0(c)\ns,j]\n\uf8f6\n\uf8f8, (13)\nwhere the approximations of 1\n\u03b3 log(1\nl\nPl\nj=1 e\u03b3E\u03c1s,j [\u03a0(c)\ns,j]) with respect to the blocks of states for all c \u2208 [m], are\n\u00b5c(\u03b3) \u2208 [0, 1], satisfying that\n\f\f\f\f\f\f\n1\n\u03b3 log\n\uf8eb\n\uf8ed1\nl\nlX\nj=1\ne\u03b3E\u03c1s,j [\u03a0(c)\ns,j]\n\uf8f6\n\uf8f8 \u2212 \u00b5c(\u03b3)\n\f\f\f\f\f\f\n\u2264 \u03b5/4. (14)\nThere exists an algorithm that outputs both an index c\u2217 and an estimated value \u02c6\u00b5c\u2217(\u03b3) such that\nPr\n\u0012\f\f\f\f\u02c6\u00b5c\u2217(\u03b3) \u2212 max\nc\u2208[m]\n\u00b5c(\u03b3)\n\f\f\f\f \u2265 \u03b5 \u222a |\u02c6\u00b5c\u2217(\u03b3) \u2212 \u00b5c\u2217(\u03b3)| \u2265\u03b5\n\u0013\n\u2264 \u03b4\nfor large enough n = \u2126(1/\u03b52).\nTo find the tilted empirical risk minimizer in the quantum learning case, we prove the following theorem. By\nsystematically minimizing the TERM, the algorithm identifies the optimal hypothesis (indexed as c\u2217) and provides\na sample complexity measure guaranteeing high-confidence probability when the sample size n is sufficiently large.",
    "a sample complexity measure guaranteeing high-confidence probability when the sample size n is sufficiently large.\nCombined with Lemma Theorem 5, Algorithm 1 retains a constant success probability in finding a projector meeting\nits threshold criterion under proper conditions in m and some constants.\nTheorem 7 (Tilted empirical risk minimization for projector-valued functions) . Let there be m possible concepts (or\nhypotheses), each of which is defined by a set of projector-valued functions hc = {\u03a0(c)\n1 , . . . ,\u03a0(c)\nn } and given a product\nstate \u03c1 = \u03c11 \u2297 \u00b7\u00b7\u00b7 \u2297\u03c1n where each \u03c1i \u2208 D(H(d)), with\n\u00b5c(\u03b3) = 1\n\u03b3 log\n \n1\nn\nnX\ni=1\ne\u03b3Tr[\u03c1i\u03a0(c)\ni ]\n!\n,11\nwhere |\u03b3| \u2208(0, \u03b5). There exists an algorithm that outputs both an index c\u2217 and an estimated value \u02c6\u00b5c\u2217(\u03b3) such that\nPr\n\u0012\f\f\f\f\u02c6\u00b5c\u2217(\u03b3) \u2212 max\nc\u2208[m]\n\u00b5c(\u03b3)\n\f\f\f\f \u2265 \u03b5 \u222a |\u02c6\u00b5c\u2217(\u03b3) \u2212 \u00b5c\u2217(\u03b3)| \u2265\u03b5\n\u0013\n\u2264 \u03b4\nfor sufficiently large n with the probability of error less than \u03b4. One can choose large enough\nn = 1\n\u03b52 log 1\n\u03b4 log2 1\n\u03b5 \u00d7 O\n\u0012\nmax\n\u0012(e|\u03b3| \u2212 1)2\n\u03b32 log\n\u0012m",
    "\u00b5c(\u03b3)\n\f\f\f\f \u2265 \u03b5 \u222a |\u02c6\u00b5c\u2217(\u03b3) \u2212 \u00b5c\u2217(\u03b3)| \u2265\u03b5\n\u0013\n\u2264 \u03b4\nfor sufficiently large n with the probability of error less than \u03b4. One can choose large enough\nn = 1\n\u03b52 log 1\n\u03b4 log2 1\n\u03b5 \u00d7 O\n\u0012\nmax\n\u0012(e|\u03b3| \u2212 1)2\n\u03b32 log\n\u0012m\n\u03b4 log 1\n\u03b4 log2 1\n\u03b5\n\u0013\n, (log m + C1)2\n\u0013\u0013\n,\nfor appropriate C1 > 0.\nProof. Let us begin by choosingn large enough so thatn \u2265 6T kl. With the conditions in Proposition 6, letl >log(Tk/\u03b4 )\n\u03b52\nfor large enough T = O(log 1\n\u03b5 ) and k = O(log 1\n\u03b4 log 1\n\u03b5 ). Each of the n observations corresponds to a single quantum\nstate \u03c1i. Since K = 2T kin Proposition 18, sample without replacement 2 T kblocks of length l from [n]. Let the sth\nblock form the product state\n\u03c1 = \u03c1s,1 \u2297 \u00b7\u00b7\u00b7 \u2297\u03c1s,l, s = 1, \u00b7\u00b7\u00b7 , 2T k\nand for each concept c \u2208 [m], the set of projectors\n{\u03a0(c)\ns,1, . . . ,\u03a0(c)\ns,l }, s = 1, \u00b7\u00b7\u00b7 , 2T k. (15)\nWithin block s, we identify\nX(c)\ns,i (\u03b3) := e\u03b3Tr[\u03c1s,i\u03a0(c)\ns,i].\nStep 1: By substituting X(c)\ns,j (\u03b3), we can apply the Proposition 18 to provide the bound on the estimation such that\n\f\f\f\f\f\f\n1\nl\nlX",
    "Within block s, we identify\nX(c)\ns,i (\u03b3) := e\u03b3Tr[\u03c1s,i\u03a0(c)\ns,i].\nStep 1: By substituting X(c)\ns,j (\u03b3), we can apply the Proposition 18 to provide the bound on the estimation such that\n\f\f\f\f\f\f\n1\nl\nlX\nj=1\nX(c)\ns,j (\u03b3) \u2212 1\nn\nnX\ni=1\ne\u03b3Tr[\u03c1i\u03a0(c)\ni ]\n\f\f\f\f\f\f\n\u2264 |e\u03b3 \u2212 1|\nr\n2 log(4T km/\u03b41)\nl , \u2200c \u2208 [m], s\u2208 [2T k], (16)\nwith the probability of error p(1)\nerr less than \u03b41. Regarding the bound on the tilted risk estimator, for \u03b3 <0, we have\n\f\f\f\f\f\f\n1\n\u03b3 log 1\nl\nlX\nj=1\nX(c)\ns,j (\u03b3) \u2212 1\n\u03b3 log 1\nn\nnX\ni=1\ne\u03b3Tr[\u03c1i\u03a0(c)\ni ]\n\f\f\f\f\f\f\n(17)\n(Log-Lipschitz) \u2264 exp(\u2212\u03b3)\n|\u03b3|\n\f\f\f\f\f\f\n1\nl\nlX\nj=1\nX(c)\ns,j (\u03b3) \u2212 1\nn\nnX\ni=1\ne\u03b3Tr[\u03c1i\u03a0(c)\ni ]\n\f\f\f\f\f\f\n(By Prop. 18) \u2264 exp(\u2212\u03b3)(1 \u2212 exp(\u03b3))\n|\u03b3|\nr\n2 log(4T km/\u03b41)\nl .\nSimilarly, for \u03b3 >0,\n\f\f\f\f\f\f\n1\n\u03b3 log 1\nl\nlX\nj=1\nX(c)\ns,j (\u03b3) \u2212 1\n\u03b3 log 1\nn\nnX\ni=1\ne\u03b3Tr[\u03c1i\u03a0(c)\ni ]\n\f\f\f\f\f\f\n\u2264 (exp(\u03b3) \u2212 1)\n|\u03b3|\nr\n2 log(4T km/\u03b41)\nl . (18)\nCombining the bound in (Eq. (17)) and (Eq. (18)), we can obtain the error bound \u03b5/4 = (exp(|\u03b3|)\u22121)\n|\u03b3|\nq\n2 log(4Tkm/\u03b4 1)\nl\nwith probability p(1)",
    "\u2264 (exp(\u03b3) \u2212 1)\n|\u03b3|\nr\n2 log(4T km/\u03b41)\nl . (18)\nCombining the bound in (Eq. (17)) and (Eq. (18)), we can obtain the error bound \u03b5/4 = (exp(|\u03b3|)\u22121)\n|\u03b3|\nq\n2 log(4Tkm/\u03b4 1)\nl\nwith probability p(1)\nerr \u2264 4T kme\u2212l\u03b32\u03b52/32(e|\u03b3|\u22121)2\n, and it follows that condition (iii) in Proposition 6 is satisfied.\nStep 2: We apply ThresholdSearch (Lemma 5) to the states \u03c1s for each odd s. For each concept c \u2208 [m], we\ninput the following two lists of projectors into the search, each with precision parameter \u03b5/4 and threshold \u03bbc:\n(1)\nn\n\u03a0(c)\ns,1, \u03a0(c)\ns,2, . . . ,\u03a0(c)\ns,l\no\nwith threshold \u03bbc + 7/4\u03b5,12\n(2)\nn\n1 \u2212 \u03a0(c)\ns,1, 1\u2212 \u03a0(c)\ns,2, . . . ,1 \u2212 \u03a0(c)\ns,l\no\nwith threshold 1 \u2212 \u03bbc \u2212 7/4\u03b5,\nIf ThresholdSearch returns a concept c for a particular odd s, we perform the measurements {\u03a0(c)\ns+1,j}j\u2208[l]\non {\u03c1s+1,j}j\u2208[l], with a list of resulting random variables\nn\nTr[\u03c1s+1,j\u03a0(c)\ns+1,j]\no\nj\u2208[l]\nand define X(c)\ns+1,j(\u03b3) := e\u03b3Tr[\u03c1s+1,j\u03a0(c)\ns+1,j]\nfor all j \u2208 [l]. If\n\f\f\f1\n\u03b3 log 1\nl\nPl\nj=1 X(c)\ns+1,j(\u03b3) \u2212 \u03bbc",
    "n\nTr[\u03c1s+1,j\u03a0(c)\ns+1,j]\no\nj\u2208[l]\nand define X(c)\ns+1,j(\u03b3) := e\u03b3Tr[\u03c1s+1,j\u03a0(c)\ns+1,j]\nfor all j \u2208 [l]. If\n\f\f\f1\n\u03b3 log 1\nl\nPl\nj=1 X(c)\ns+1,j(\u03b3) \u2212 \u03bbc\n\f\f\f > \u03b5is satisfied, the check is considered passed, and we output c. If\nnone of the checks pass, we declare a failure.\nNext we analyze two error scenarios and the corresponding probabilities:\n(a) Suppose there exists c such that |\u00b5c \u2212 \u03bbc| \u22652\u03b5. By condition (iii) in Lemma 2 in [31], it follows that\f\f\f1/l Pl\nj=1 E\u03c1s,j\nh\n\u03a0(c)\ns,j\ni\n\u2212 \u03bbc\n\f\f\f \u2265 7/4\u03b5. This implies:\n1/l\nlX\nj=1\nE\u03c1s,j\nh\n\u03a0(c)\ns,j\ni\n\u2265 \u03bbc + 7/4\u03b5, or 1 /l\nlX\nj=1\nE\u03c1s,j\nh\n1 \u2212 \u03a0(c)\ns,j\ni\n\u2264 1 \u2212 \u03bbc \u2212 7/4\u03b5.\nSince ThresholdSearch guarantees that if the projector or its complement exceeds the specified threshold, the\nalgorithm returns that concept with probability at least 0 .03. We conclude that each time ThresholdSearch is\nperformed on the pair of projector lists, it outputs a concept c such that\n\f\f\f1/l Pl\nj=1 E\u03c1s,j\nh\n\u03a0(c)\ns,j\ni\n\u2212 \u03bbc\n\f\f\f > 6/4\u03b5. For",
    "performed on the pair of projector lists, it outputs a concept c such that\n\f\f\f1/l Pl\nj=1 E\u03c1s,j\nh\n\u03a0(c)\ns,j\ni\n\u2212 \u03bbc\n\f\f\f > 6/4\u03b5. For\nsuch a concept c, and for any \u03b3 \u2208 R, consider the quantity\n\u2206(\u03b3) =\n\f\f\f\f\f\f\n1\n\u03b3 log 1\nl\nlX\nj=1\nexp\n\u0010\n\u03b3E\u03c1s,j [\u03a0(c)\ns,j]\n\u0011\n\u2212 1\nl\nlX\nj=1\nE\u03c1s,j [\u03a0(c)\ns,j]\n\f\f\f\f\f\f\n(19)\nNoted that \u00afEs,j =\nlP\nj=1\nE\u03c1s,j [\u03a0(c)\ns,j]. To bound \u2206( \u03b3) from above, let\n\u03b4j = E\u03c1s,j [\u03a0(c)\ns,j] \u2212 \u00afEs,j, (20)\nsuch that 1\nl\nPl\nj=1 \u03b4j = 0. Therefore, we obtain\n1\n\u03b3 log\n\uf8eb\n\uf8ed1\nl\nlX\nj=1\ne\u03b3E\u03c1s,j [\u03a0(c)\ns,j]\n\uf8f6\n\uf8f8 = 1\n\u03b3\n\uf8ee\n\uf8f0\u03b3 \u00afEs,j + log\n\uf8eb\n\uf8ed1\nl\nlX\nj=1\ne\u03b3\u03b4j\n\uf8f6\n\uf8f8\n\uf8f9\n\uf8fb = \u00afEs,j + 1\n\u03b3 log\n\uf8eb\n\uf8ed1\nl\nlX\nj=1\ne\u03b3\u03b4j\n\uf8f6\n\uf8f8 = \u00afEs,j + \u2206(\u03b3). (21)\nSince E\u03c1s,j [\u03a0(c)\ns,j] \u2208 [0, 1] for each j, then \u00afEs,j \u2208 [0, 1] and thus each deviation \u03b4j \u2208 [\u2212 \u00afEs,j, 1 \u2212 \u00afEs,j] \u2286 [\u22121, 1].\nConsequently, {\u03b4j} is a zero-mean set bounded by \u00b11.\nApplying Hoeffding\u2019s Lemma, for every \u03b3 \u2208 R,\n1\nl\nlX\nj=1\ne\u03b3\u03b4j \u2264 exp\n\u0012\u03b32\n8\n\u0013\n. (22)\nTaking logarithms and dividing by \u03b3 >0\n0 \u2264 \u2206(\u03b3) \u2264 1\n\u03b3 log\n\uf8eb\n\uf8ed1\nl\nlX\nj=1\ne\u03b3\u03b4j\n\uf8f6\n\uf8f8 \u2264 \u03b3\n8 (23)",
    "Applying Hoeffding\u2019s Lemma, for every \u03b3 \u2208 R,\n1\nl\nlX\nj=1\ne\u03b3\u03b4j \u2264 exp\n\u0012\u03b32\n8\n\u0013\n. (22)\nTaking logarithms and dividing by \u03b3 >0\n0 \u2264 \u2206(\u03b3) \u2264 1\n\u03b3 log\n\uf8eb\n\uf8ed1\nl\nlX\nj=1\ne\u03b3\u03b4j\n\uf8f6\n\uf8f8 \u2264 \u03b3\n8 (23)\nBy an analogous argument (applied to \u2212\u03b3) one obtains \u2206( \u03b3) \u2265 \u2212|\u03b3|\n8 . Thus for every real \u03b3 \u0338= 0, |\u2206(\u03b3)| \u2264|\u03b3|\n8 . In\nparticular, if we desire |\u2206(\u03b3)| \u2208O(\u03b5), it suffices to choose |\u03b3| \u2208(0, \u03b5), i.e., \u03b3 is sufficiently small.\nFinally, we apply multiplicative Chernoff bound to have\nPr\n\uf8eb\n\uf8ed\n\f\f\f\f\f\f\n1\n\u03b3 log 1\nl\nlX\nj=1\nX(c)\ns+1,j(\u03b3) \u2212 \u03bbc\n\f\f\f\f\f\f\n\u2264 \u03b5\n\uf8f6\n\uf8f8 (24)13\n= Pr\n\uf8eb\n\uf8ed\n\f\f\f\f\f\f\n1\n\u03b3 log 1\nl\nlX\nj=1\nX(c)\ns+1,j(\u03b3) \u2212 1\nl\nlX\nj=1\nE\u03c1s,j [\u03a0(c)\ns,j] + 1\nl\nlX\nj=1\nE\u03c1s,j [\u03a0(c)\ns,j] \u2212 \u03bbc\n\f\f\f\f\f\f\n\u2264 \u03b5\n\uf8f6\n\uf8f8\n(Triangle Ineq.) \u2264 Pr\n\uf8eb\n\uf8ed\n\f\f\f\f\f\f\n|1\n\u03b3 log 1\nl\nlX\nj=1\nX(c)\ns+1,j(\u03b3) \u2212 1\nl\nlX\nj=1\nE\u03c1s,j [\u03a0(c)\ns,j]| \u2212 |1\nl\nlX\nj=1\nE\u03c1s,j [\u03a0(c)\ns,j] \u2212 \u03bbc|\n\f\f\f\f\f\f\n\u2264 \u03b5\n\uf8f6\n\uf8f8\n\u2264 Pr\n\uf8eb\n\uf8ed\n\f\f\f\f\f\f\n1\n\u03b3 log 1\nl\nlX\nj=1\nX(c)\ns+1,j(\u03b3) \u2212 1\nl\nlX\nj=1\nE\u03c1s,j [\u03a0(c)\ns,j]\n\f\f\f\f\f\f\n\u2265 \u03b5/2\n\uf8f6\n\uf8f8\n(Let Es,j := E\u03c1s,j [\u03a0(c)\ns,j]) = Pr\n\uf8eb\n\uf8ed\n\f\f\f\f\f\f\n1\n\u03b3 log 1\nl\nlX\nj=1\nX(c)\ns+1,j(\u03b3) \u2212 1\n\u03b3 log 1\nl\nlX",
    "\uf8f6\n\uf8f8\n\u2264 Pr\n\uf8eb\n\uf8ed\n\f\f\f\f\f\f\n1\n\u03b3 log 1\nl\nlX\nj=1\nX(c)\ns+1,j(\u03b3) \u2212 1\nl\nlX\nj=1\nE\u03c1s,j [\u03a0(c)\ns,j]\n\f\f\f\f\f\f\n\u2265 \u03b5/2\n\uf8f6\n\uf8f8\n(Let Es,j := E\u03c1s,j [\u03a0(c)\ns,j]) = Pr\n\uf8eb\n\uf8ed\n\f\f\f\f\f\f\n1\n\u03b3 log 1\nl\nlX\nj=1\nX(c)\ns+1,j(\u03b3) \u2212 1\n\u03b3 log 1\nl\nlX\nj=1\ne\u03b3Es,j + 1\n\u03b3 log 1\nl\nlX\nj=1\ne\u03b3Es,j \u2212 1\nl\nlX\nj=1\nE\u03c1s,j\n\f\f\f\f\f\f\n\u2265 \u03b5/2\n\uf8f6\n\uf8f8\n(Triangle Ineq.) \u2264 Pr\n\uf8eb\n\uf8ed\n\f\f\f\f\f\f\n1\n\u03b3 log 1\nl\nlX\nj=1\nX(c)\ns+1,j(\u03b3) \u2212 1\n\u03b3 log 1\nl\nlX\nj=1\ne\u03b3Es,j\n\f\f\f\f\f\f\n+\n\f\f\f\f\f\f\n1\n\u03b3 log 1\nl\nlX\nj=1\ne\u03b3Es,j \u2212 1\nl\nlX\nj=1\nE\u03c1s,j\n\f\f\f\f\f\f\n\u2265 \u03b5/2\n\uf8f6\n\uf8f8\n(Jensen\u2019s Ineq.) \u2264 Pr\n\uf8eb\n\uf8ed\n\f\f\f\f\f\f\n1\n\u03b3 log 1\nl\nlX\nj=1\nX(c)\ns+1,j(\u03b3) \u2212 1\n\u03b3 log 1\nl\nlX\nj=1\ne\u03b3Es,j\n\f\f\f\f\f\f\n\u2265 \u03b5/4\n\uf8f6\n\uf8f8\n(Log-Lipschitz)\n\uf8f1\n\uf8f2\n\uf8f3\n\u2264 Pr\n\u0010\f\f\f1\nl\nPl\nj=1 X(c)\ns+1,j(\u03b3) \u2212 1\nl\nPl\ni=1 e\u03b3Es,j\n\f\f\f \u2265 |\u03b3|e\u03b3\u03b5/4\n\u0011\n(\u03b3 <0)\n\u2264 Pr\n\u0010\f\f\f1\nl\nPl\nj=1 X(c)\ns+1,j(\u03b3) \u2212 1\nl\nPl\ni=1 e\u03b3Es,j\n\f\f\f \u2265 |\u03b3|\u03b5/4\n\u0011\n(\u03b3 >0)\n(By Prop. 15)\n(\n\u2264 2e\u2212l|\u03b3|e\u03b3\u03b52/12(1\u2212e\u03b3) (\u03b3 <0)\n\u2264 2e\u2212l|\u03b3|\u03b52/12(e\u03b3\u22121) (\u03b3 >0)\n= 2e\u2212l|\u03b3|\u03b52/12(e|\u03b3|\u22121)\nThus, it shows that when |\u00b5c \u2212 \u03bbc| \u22652\u03b5, the probability of the check passing is at least 1 \u2212 2e\u2212l|\u03b3|\u03b52/12(e|\u03b3|\u22121).",
    "(\n\u2264 2e\u2212l|\u03b3|e\u03b3\u03b52/12(1\u2212e\u03b3) (\u03b3 <0)\n\u2264 2e\u2212l|\u03b3|\u03b52/12(e\u03b3\u22121) (\u03b3 >0)\n= 2e\u2212l|\u03b3|\u03b52/12(e|\u03b3|\u22121)\nThus, it shows that when |\u00b5c \u2212 \u03bbc| \u22652\u03b5, the probability of the check passing is at least 1 \u2212 2e\u2212l|\u03b3|\u03b52/12(e|\u03b3|\u22121).\n(b) When a concept is chosen with |\u00b5c \u2212 \u03bbc| \u2264\u03b5/2, the proof is similar as (Eq. (24)) such that\nPr\n\uf8eb\n\uf8ed\n\f\f\f\f\f\f\n1\n\u03b3 log 1\nl\nlX\nj=1\nX(c)\ns+1,j(\u03b3) \u2212 \u03bbc\n\f\f\f\f\f\f\n\u2265 \u03b5\n\uf8f6\n\uf8f8 (25)\n= Pr\n\uf8eb\n\uf8ed\n\f\f\f\f\f\f\n1\n\u03b3 log 1\nl\nlX\nj=1\nX(c)\ns+1,j(\u03b3) \u2212 1\nl\nlX\nj=1\nE\u03c1s,j [\u03a0(c)\ns,j] + 1\nl\nlX\nj=1\nE\u03c1s,j [\u03a0(c)\ns,j] \u2212 \u03bbc\n\f\f\f\f\f\f\n\u2265 \u03b5\n\uf8f6\n\uf8f8\n(Triangle Ineq.) \u2264 Pr\n\uf8eb\n\uf8ed|1\n\u03b3 log 1\nl\nlX\nj=1\nX(c)\ns+1,j(\u03b3) \u2212 1\nl\nlX\nj=1\nE\u03c1s,j [\u03a0(c)\ns,j]| + |1\nl\nlX\nj=1\nE\u03c1s,j [\u03a0(c)\ns,j] \u2212 \u03bbc| \u2265\u03b5\n\uf8f6\n\uf8f8\n\u2264 Pr\n\uf8eb\n\uf8ed|1\n\u03b3 log 1\nl\nlX\nj=1\nX(c)\ns+1,j(\u03b3) \u2212 1\nl\nlX\nj=1\nE\u03c1s,j [\u03a0(c)\ns,j]| \u2265\u03b5/2\n\uf8f6\n\uf8f8\n\u2264 2e\u2212l|\u03b3|\u03b52/12(e|\u03b3|\u22121).\nWhen |\u00b5c \u2212 \u03bbc| \u2264\u03b5/2, the probability of the check passing is ( \u2264 2e\u2212l|\u03b3|\u03b52/12(e|\u03b3|\u22121)). This means the algorithm is\nunlikely to output such concepts, as they do not represent significant deviations from the threshold. Therefore, the",
    "unlikely to output such concepts, as they do not represent significant deviations from the threshold. Therefore, the\nalgorithm should select concepts c\u2217 such that |\u00b5c\u2217 \u2212 \u03bbc\u2217| \u2265\u03b5/2.\nThe Algorithm 2 thus can be applied to obtain a good estimate if|maxc \u02c6\u00b5c(\u03b3)\u2212\u00b5c\u2217(\u03b3)| \u22652\u03b5 and |\u02c6\u00b5c\u2217(\u03b3)\u2212\u00b5c\u2217(\u03b3)| \u2265\n\u03b5/2.\nBy an argument analogous to the error proof as in Lemma 2 in Ref. [31], the probability of error is bounded by\np(2)\nerr \u2264 T(0.97k + 2(k + 1)e\u2212l|\u03b3|\u03b52/12(e|\u03b3|\u22121)).\nFinally, we take the length of a block as\nl = O\n\u0012 1\n\u03b52 max((e|\u03b3| \u2212 1)2\n\u03b32 log(T km/\u03b4), (log m + C1)2)\n\u0013\n, (26)14\nand the sample complexity as\nn = T k\u00d7 O\n\u0012 1\n\u03b52 max((e|\u03b3| \u2212 1)2\n\u03b32 log(T km/\u03b4), (log m + C1)2)\n\u0013\n= 1\n\u03b52 log 1\n\u03b4 log2 1\n\u03b5 \u00d7 O\n\u0012\nmax\n\u0012(e|\u03b3| \u2212 1)2\n\u03b32 log\n\u0012m\n\u03b4 log 1\n\u03b4 log2 1\n\u03b5\n\u0013\n, (log m + C1)2\n\u0013\u0013\n,\nensuring that the total error probability p(1)\nerr + p(2)\nerr \u2264 \u03b4. Furthermore, when \u03b3 \u2192 0, the sample complexity recovers\nto the complexity of the standard ERM algorithm in Fact 1.",
    "\u0013\u0013\n,\nensuring that the total error probability p(1)\nerr + p(2)\nerr \u2264 \u03b4. Furthermore, when \u03b3 \u2192 0, the sample complexity recovers\nto the complexity of the standard ERM algorithm in Fact 1.\nThe algorithm used in Theorem 7 is formulated as Algorithm 2 in Sec. IX B. The guarantees of this algorithm are\ngiven in Proposition 6.\nIV. PAC GENERALIZATION BOUND OF TERM\nExtensive analysis of the generalization error in Ref. [13] motivated the introduction of the new measure, namely\nthat of the tilted generalization error. The tilted generalization error is the difference between the tilted empirical risk\non the training set and its expected value over the data distribution R(f) relative to unknown concept f. Formally,\nthe tilted generalization error is defined by Ref. [13] as follows:\nTilted Generalization Error := R(f) \u2212 eR\u03b3(f). (27)\nThe parameter \u03b3 controls the tilt value. By Lemma 4, for \u03b3 \u2192 0, it recovers the standard generalization error;",
    "Tilted Generalization Error := R(f) \u2212 eR\u03b3(f). (27)\nThe parameter \u03b3 controls the tilt value. By Lemma 4, for \u03b3 \u2192 0, it recovers the standard generalization error;\nfor \u03b3 \u2192 \u221e, it approximates the behavior of the worst-case loss. Considerations of tilted losses in quantum settings,\nincluding the definitions provided in this paper, require adopting the tilted generalization error paradigm. These ideas\nare further motivated in the next section as future work suggestions. The following theorem discussed in this section\ncorresponds to a measure of the generalization error with respect to our definition of QTERM. The convergence of the\ntilted empirical risk to the true risk is shown as follows. For reference, the PAC bound of ERM for learning concept\nclasses via the covering number is shown in Refs. [48, 50].\nTheorem 8 (PAC Generalization Bound of TERM via Uniform Covering Numbers) . Consider hypotheses h in any",
    "classes via the covering number is shown in Refs. [48, 50].\nTheorem 8 (PAC Generalization Bound of TERM via Uniform Covering Numbers) . Consider hypotheses h in any\nconcept class F and loss function taking value in [0, 1], for \u03b3 \u2208 (0, \u03b5) and any probability distribution D, we denote\nthe tilted empirical risk as eR\u03b3(h) and the corresponding population risk R(h) as EZ\u223cD[L(h, Z)]. For any \u03b5 >0, over\nsamples S, we obtain that\nPr\nS\u223cDn\nh\n\u2203h \u2208 F:\n\f\f\fR(h) \u2212 eR\u03b3(h)\n\f\f\f \u2265 \u03b5\ni\n\u2264 8\u03931\n\u0010\n2n, \u03b5\n8, GF,L,\u03b3\n\u0011\nexp\n\u0012\n\u2212 n\u03b52\n32|e\u03b3 \u2212 1|2\n\u0013\n, (28)\nwhere \u03931\n\u0000\n2n, \u03b5\n8 , GF,L,\u03b3\n\u0001\nis the covering number of GF,L,\u03b3 on a sample of size 2n within error \u03b5\n8 .\nProof. We remind readers that the tilted empirical risk is defined as in Definition 2:\neR\u03b3(h) := 1\n\u03b3 log\n \n1\nn\nnX\ni=1\nexp (\u03b3 L(h, Zi))\n!\n, (29)\nwhere {Zi}n\ni=1 are i.i.d. samples from an unknown distribution D, and L(h, Z) \u2208 [0, a] is a bounded loss. We wish to\nshow that, with high probability, eR\u03b3(h) is uniformly close (over all hypotheses h) to the true risk",
    "show that, with high probability, eR\u03b3(h) is uniformly close (over all hypotheses h) to the true risk\nR(h) = EZ\u223cD [L(h, Z)] . (30)\nFor simplicity, we denote each data point by Zi = (Xi, Yi). The proof will follow in three steps, using the same\ntechniques as the proof of PAC bound of empirical risk, namely symmetrization, concentration, and lifting the bound\nfrom the cover to all h \u2208 Fin Ref. [48, 50].\n(i) Symmetrization. Let F be a family of hypotheses h : X \u2192bY. Let L : F \u00d7Z \u2192[0, a] be a bounded loss function.\nWe have an i.i.d. sample S = {Z1, . . . , Zn} from D. Let S\u2032 = {Z\u2032\n1, . . . , Z\u2032\nn} be an independent ghost sample 2 of the\n2 A ghost sample is another sequence of data in all identical to the training data S.15\nsame size n, also drawn randomly from D. Define its tilted empirical risk\neR\u2032\n\u03b3(h) = 1\n\u03b3 log\n \n1\nn\nnX\ni=1\nexp (\u03b3 L(h, Z\u2032\ni))\n!\n. (31)\nand the corresponding empirical risk as \u02c6R\u2032(h) = 1\nn\nPn\ni=1 L(h, Z\u2032\ni). By triangle inequality, if |R(h) \u2212 eR\u03b3(h)| \u2265\u03b5, in",
    "eR\u2032\n\u03b3(h) = 1\n\u03b3 log\n \n1\nn\nnX\ni=1\nexp (\u03b3 L(h, Z\u2032\ni))\n!\n. (31)\nand the corresponding empirical risk as \u02c6R\u2032(h) = 1\nn\nPn\ni=1 L(h, Z\u2032\ni). By triangle inequality, if |R(h) \u2212 eR\u03b3(h)| \u2265\u03b5, in\nterms of indicator functions there exists\n1 {|R(h) \u2212 eR\u03b3(h)| \u2265\u03b5}1 {\n\f\f\fR(h) \u2212 \u02c6R\u2032(h)\n\f\f\f \u2264 \u03b5\n2}1 {| eR\u2032\n\u03b3(h) \u2212 \u02c6R\u2032(h)| \u2264\u03b5\n4} \u22641 {| eR\u2032\n\u03b3(h) \u2212 eR\u03b3(h)| \u2265\u03b5\n4}. (32)\nTaking the expectation value with respect to S\u2032 in Eq. (32), and using Hoeffding\u2019s inequality together with the\nassumption on n that n \u2265 4c2\u03b5\u22122 ln 2, it leads to\nES\u2032\nh\n1 {|R(h) \u2212 \u02c6R\u2032(h)| \u2264\u03b5\n2}\ni\n\u2265 1 \u2212 2 exp[\u2212\u03b52n\n2c2 ] \u2265 1\n2. (33)\nFor the last term in Eq. (32),\nES\u2032\nh\n1 {| eR\u2032\n\u03b3(h) \u2212 eR\u03b3(h)| \u2265\u03b5\n4}\ni\n= Pr\nS\u2032\nh\n\u2203h \u2208 F:\n\f\f\feR\u2032\n\u03b3(h) \u2212 eR\u03b3(h)\n\f\f\f \u2265 \u03b5\n4\ni\n. (34)\nSimilarly for the third term, under the assumption on tilting that \u03b3 \u2208 (0, \u03b5) in Theorem 7, for 0 < \u03b4\u2264 1\n2 , we use\nPr\nS\u2032\nh\n\u2203h \u2208 F: | eR\u2032\n\u03b3(h) \u2212 \u02c6R\u2032(h)| \u2264\u03b5\n4\ni\n= ES\u2032\nh\n1 {| eR\u2032\n\u03b3(h) \u2212 \u02c6R\u2032(h)| \u2264\u03b5\n4}\ni\n\u2265 1 \u2212 \u03b4 \u2265 1\n2. (35)\nInsert the bounds above into Eq. (32), we therefore obtain\nPr\nS\nh",
    "2 , we use\nPr\nS\u2032\nh\n\u2203h \u2208 F: | eR\u2032\n\u03b3(h) \u2212 \u02c6R\u2032(h)| \u2264\u03b5\n4\ni\n= ES\u2032\nh\n1 {| eR\u2032\n\u03b3(h) \u2212 \u02c6R\u2032(h)| \u2264\u03b5\n4}\ni\n\u2265 1 \u2212 \u03b4 \u2265 1\n2. (35)\nInsert the bounds above into Eq. (32), we therefore obtain\nPr\nS\nh\n\u2203h \u2208 F: |R(h) \u2212 eR\u03b3(h)| \u2265\u03b5\ni\n\u2264 4 Pr\nS,S\u2032\nh\n\u2203h \u2208 F: | eR\u2032\n\u03b3(h) \u2212 eR\u03b3(h)| \u2265\u03b5\n4\ni\n. (36)\n(ii) Concentration. Let\u2019s merge the samples,\nT = (S, S\u2032) = (Z1, . . . , Zn, Z\u2032\n1, . . . , Z\u2032\nn) . (37)\nHence |T| = 2n. For \u03b3 \u2208 (0, \u03b5), let us denote the \u201cexponential loss-function classes\u201d:\nGF,L,\u03b3 =\nn\ngh(z) = exp(\u03b3L(h, z))\n\f\f\f h \u2208 F\no\n. (38)\nSuppose that L(h, z) \u2208 [0, a] with gh(z) \u2208 [1, e\u03b3a]. By definition, there exists a finite set of functions {g1, . . . , gM } \u2282\nGF,L,\u03b3 such that: For every h \u2208 F, there is some j \u2208 {1, . . . , M} with maxz\u2208T |gh(z) \u2212 gj(z)| \u2264\u03b7, for some chosen\n\u03b7 >0. The minimal such M is \u03931 (2n, \u03b7,GF,L,\u03b3), the uniform covering number of GF,L,\u03b3 on a sample of size 2 n.\nSuppose we fix some gj. Then\nb\u03a6(gj) := 1\nn\nnX\ni=1\ngj(Zi), b\u03a6\u2032(gj) := 1\nn\nnX\ni=1\ngj(Z\u2032\ni). (39)",
    "Suppose we fix some gj. Then\nb\u03a6(gj) := 1\nn\nnX\ni=1\ngj(Zi), b\u03a6\u2032(gj) := 1\nn\nnX\ni=1\ngj(Z\u2032\ni). (39)\nSince gj(z) \u2208 [1, e\u03b3a], we define d(\u03b3, a) = |1 \u2212 e\u03b3a| and apply Hoeffding\u2019s inequality to obtain\nPr\nh\f\f\fb\u03a6\u2032(gj) \u2212 b\u03a6(gj)\n\f\f\f \u2265 t\ni\n\u2264 2 exp\n\u0012\n\u2212 nt2\n2d2(\u03b3, c)\n\u0013\n. (40)\nApplying a union bound over j = 1, . . . , M, we get\nPr\nh\n\u2203j :\n\f\f\fb\u03a6\u2032(gj) \u2212 b\u03a6(gj)\n\f\f\f \u2265 t\ni\n\u2264 M \u00b7 2 exp\n\u0012\n\u2212 nt2\n2d2(\u03b3, c)\n\u0013\n. (41)\nHence, choosing t suitably as \u03b5\n4 , with probability at least\n1 \u2212 2\u03931 (2n, \u03b7,GF,L,\u03b3) exp\n\u0012\n\u2212 n\u03b52\n32d2(\u03b3, c)\n\u0013\n, (42)16\nall the elements {gj} have\n\f\f\flog(b\u03a6\u2032(gj)) \u2212 log(b\u03a6(gj))\n\f\f\f \u2264 |b\u03a6\u2032(gj)\u2212b\u03a6(gj)|\nmin(1,e\u03b3a) \u2264 \u03b5\n4 if a = 1.\n(iii) Lifting the bound from the cover to all h \u2208 F. Now, take any h \u2208 F. By construction, it is \u03b7-close (in \u2113\u221e on\nsample T) to one of the cover elements, say gj. Specifically,\nmax\nZi\u2208T\n\f\f\fb\u03a6(h) \u2212 b\u03a6(gj)\n\f\f\f = max\nZi\u2208T\n\f\f\f\f\f\n1\nn\nnX\ni=1\n\u0010\ne\u03b3L(h,Zi) \u2212 gj(Zi)\n\u0011\f\f\f\f\f \u2264 \u03b7, (43)\nand similarly for the ghost sample. But we must ensure every h \u2208 Fcannot exceed \u03b5",
    "max\nZi\u2208T\n\f\f\fb\u03a6(h) \u2212 b\u03a6(gj)\n\f\f\f = max\nZi\u2208T\n\f\f\f\f\f\n1\nn\nnX\ni=1\n\u0010\ne\u03b3L(h,Zi) \u2212 gj(Zi)\n\u0011\f\f\f\f\f \u2264 \u03b7, (43)\nand similarly for the ghost sample. But we must ensure every h \u2208 Fcannot exceed \u03b5\n2 , suppose that by decomposition\n\f\f\flog(b\u03a6\u2032(h)) \u2212 log(b\u03a6(h))\n\f\f\f \u2264\n\f\f\flog(b\u03a6\u2032(h)) \u2212 log(b\u03a6\u2032(gj))\n\f\f\f +\n\f\f\flog(b\u03a6\u2032(gj)) \u2212 log(b\u03a6(gj))\n\f\f\f +\n\f\f\flog(b\u03a6(gj)) \u2212 log(b\u03a6(h))\n\f\f\f. (44)\nIndeed, b\u03a6(h) and b\u03a6(gj) differ by at most \u03b7 in average, so their logs also differ by \u2264 \u03b7 when c = 1 for chosen \u03b3, which\nwe choose to be \u2264 \u03b5/8. Similarly for b\u03a6\u2032(h) or b\u03a6\u2032(gj). Hence, no such gj in the middle term can exceed \u03b5\n4 with high\nprobability derived in concentration step.\nFinally, putting it all together, we obtain the desired uniform bound:\nPr\nS\u223cDn\nh\n\u2203h \u2208 F:\n\f\f\fR(h) \u2212 eR\u03b3(h)\n\f\f\f \u2265 \u03b5\ni\n\u2264 8\u03931\n\u0010\n2n, \u03b5\n8, GF,L,\u03b3\n\u0011\nexp\n\u0012\n\u2212 n\u03b52\n32|e\u03b3 \u2212 1|2\n\u0013\n. (45)\nThis completes the proof of the PAC-type (uniform convergence) guarantee for the tilted empirical risk.",
    "h\n\u2203h \u2208 F:\n\f\f\fR(h) \u2212 eR\u03b3(h)\n\f\f\f \u2265 \u03b5\ni\n\u2264 8\u03931\n\u0010\n2n, \u03b5\n8, GF,L,\u03b3\n\u0011\nexp\n\u0012\n\u2212 n\u03b52\n32|e\u03b3 \u2212 1|2\n\u0013\n. (45)\nThis completes the proof of the PAC-type (uniform convergence) guarantee for the tilted empirical risk.\nRemark. When hypotheses are implemented via parametrized quantum circuits with specific data-encoding strate-\ngies, one can leverage encoding-dependent generalization bounds in Ref. [51] to obtain explicit estimates of the covering\nnumbers for the tilted-loss class under that encoding.\nIn quantum learning settings, it is common to bound the function-class covering number \u0393 1(n, \u03b5,GF,L,\u03b3) by the\noperator-class covering number \u0393 1,q(n, \u03b5,C). This arises since each real-valued function in GF,L,\u03b3 originates from\nmeasuring operators in C, thus yielding \u03931(n, \u03b5,GF,L,\u03b3) \u2264 \u03931,q(n, \u03b5,C). Therefore, the function-class covering number\nappearing in the PAC bound established in Theorem 8 can generally be bounded by the operator-class covering",
    "appearing in the PAC bound established in Theorem 8 can generally be bounded by the operator-class covering\nnumber, thus facilitating concrete bounds on the learnability of quantum hypothesis classes via TERM. In the next\nsection, we will define uniform convergence of QTERM for agnostic learnability bounds.\nV. STATISTICAL LEARNING FOR PROJECTOR-VALUED FUNCTIONS\nIn this section, we present a lemma which ensures that optimizing the TERM over \u03b5-net of the concept class\ndepending on classical data, yields a solution that closely approximates the true risk minimizer.\nLemma 9 (Uniform Convergence of QTERM). Given l0 samples drawn from the classical-quantum distribution\n\u03c1 =\nX\nx\u2208X\nD(x)|x\u27e9\u27e8x| \u2297\u03c1(x), (46)\none can construct a finite subset C\u03b5/2 \u2286 Cwith respect to the loss function L whose size obeys |C\u03b5/2| \u2264\u03931,q(l0, \u03b5/2, C).\nFor each hypothesis h \u2208 C, there exists a known h\u2217 \u2208 C\u03b5/2 such that\n|R(h) \u2212 R(h\u2217)| \u2264\u03b5. (47)",
    "For each hypothesis h \u2208 C, there exists a known h\u2217 \u2208 C\u03b5/2 such that\n|R(h) \u2212 R(h\u2217)| \u2264\u03b5. (47)\nFurthermore, with high probability, the tilted empirical risk uniformly approximates the true risk\n\u2200h \u2208 C: |R(h) \u2212 eR\u03b3(h)| < \u03b5/4, (48)\nwith probability of error at most\nperr, unif \u2264 8\u03931,q(2l0, \u03b5/128, C)e\n\u2212 l0\u03b52\n512|e\u03b3\u22121|2 . (49)17\nProof. Apply the PAC bound of TERM derived in Theorem 8 to a sample S of size l0, where each sample is drawn\nindependently from distribution D. With probability at least 1 \u2212 perr, unif, we have that for tilted risk eR\u03b3(h),\nPr\nS\u223cD\nh\n\u2203h \u2208 C: |R(h) \u2212 eR\u03b3(h)| \u2265\u03b5/4\ni\n\u2264 8\u03931,q(2l0, \u03b5/128, C)e\n\u2212 l0\u03b52\n512|e\u03b3\u22121|2 . (50)\nwhere R(h) denotes the true risk under the chosen loss function. Construct an \u03b5/2-net C\u03b5/2(\u20d7 x) with respect to the\npseudo-metric dr(g1, g2) = | eR\u03b3(g1) \u2212 eR\u03b3(g2)| on the data \u20d7 x. By definition of net, for every h \u2208 Cthere is h\u2217 \u2208 C\u03b5/2(\u20d7 x)\nsuch that\n| eR\u03b3(h) \u2212 eR\u03b3(h\u2217)| \u2264\u03b5/2. (51)",
    "pseudo-metric dr(g1, g2) = | eR\u03b3(g1) \u2212 eR\u03b3(g2)| on the data \u20d7 x. By definition of net, for every h \u2208 Cthere is h\u2217 \u2208 C\u03b5/2(\u20d7 x)\nsuch that\n| eR\u03b3(h) \u2212 eR\u03b3(h\u2217)| \u2264\u03b5/2. (51)\nWith the assumptions from Theorem 8 in hand, for any h \u2208 C, with high probability, we have\n|R(h) \u2212 R(h\u2217)| \u2264 |R(h) \u2212 eR\u03b3(h)| + | eR\u03b3(h) \u2212 eR\u03b3(h\u2217)| + |R(h\u2217) \u2212 eR\u03b3(h\u2217)| (52)\n\u2264 2 sup\nh\u2208C\n|R(h) \u2212 eR\u03b3(h)| + \u03b5/2\n\u2264 \u03b5.\nRemark. The choice of loss function determines which Schatten- q seminorm (e.g., q = 1 for trace-distance losses,\nq = \u221e for operator-norm losses) is used to define the pseudometric between two concepts.\nVia this lemma, we decompose the learning task into two stages: using classical data to construct an \u03b5-net over\nthe concept space, and then using quantum data to select an optimal hypothesis from this finite subset. The \u03b5-net\nensures coverage of the true risk landscape, while the quantum component enables effective hypothesis selection under",
    "ensures coverage of the true risk landscape, while the quantum component enables effective hypothesis selection under\nthe TERM framework. This decomposition provides a practical and theoretically grounded approach to regularized\nlearning from quantum data. We now formalize these in the following theorem on the agnostic learnability of QTERM\nframework.\nTheorem 10 (Agnostic Learnability of Projector-Valued Functions via QTERM). Let C be a concept class consisting\nof a set of projectors hc := {\u03a0(c)\n1 , \u00b7\u00b7\u00b7 , \u03a0(c)\nn }m\nc=1 and let \u03b5 >0. Given training samples S = {(xi, \u03c1i)}n\ni=1 with xi \u223c D\nand \u03c1i produced by an unknown classical-quantum channel, there exists an agnostic learning algorithm A that, for\nfixed \u03b3 in a proven range, outputs a hypothesis c\u2217 \u2208 Calong with an estimate \u02c6\u00b5c\u2217(\u03b3) of 1 \u2212 beR\u03b3(c) such that\nPr\n\u0012\f\f\f\f\u02c6\u00b5c\u2217(\u03b3) \u2212 inf\nc\u2208C\n\u00b5c(\u03b3)\n\f\f\f\f \u2265 3\u03b5 \u222a |\u02c6\u00b5c\u2217(\u03b3) \u2212 \u00b5c\u2217(\u03b3)| \u22652\u03b5\n\u0013\n:= perr, (53)\nif the covering numbers satisfy\nlim\nn\u2192\u221e\nlog2 \u03931,\u221e(n, \u03b5,C)\nn = 0, \u2200\u03b5 >0. (54)",
    "Pr\n\u0012\f\f\f\f\u02c6\u00b5c\u2217(\u03b3) \u2212 inf\nc\u2208C\n\u00b5c(\u03b3)\n\f\f\f\f \u2265 3\u03b5 \u222a |\u02c6\u00b5c\u2217(\u03b3) \u2212 \u00b5c\u2217(\u03b3)| \u22652\u03b5\n\u0013\n:= perr, (53)\nif the covering numbers satisfy\nlim\nn\u2192\u221e\nlog2 \u03931,\u221e(n, \u03b5,C)\nn = 0, \u2200\u03b5 >0. (54)\nAnd perr can be made arbitrarily small provided that n = 6T kl, and T = O(log 1\n\u03b5 ) and k = O(log 1\n\u03b4 log 1\n\u03b5 ), for constants\nC1, C2, C3 and l such that\n(log \u03931,\u221e(6T kl, \u03b5/2, C)) + C2)2 \u2264 C1l\u03b52, (55)\nwe have\nperr \u2264 \u03b4\n2 + C3T k\u03931,\u221e(6T kl, \u03b5/2, C)e\n\u2212 l|\u03b3|\u03b52\n12(e|\u03b3|\u22121) ) + 8\u03931,\u221e(12T kl, \u03b5/128, C)e\u2212 6Tkl\u03b52\n512|e\u03b3\u22121| . (56)\nProof. The failure probability perr is decomposed into two independent contributions, each bounded by \u03b4/2 such that\nperr \u2264 perr,unif + perr,TERM \u2264 \u03b4. (57)\nThe proof proceeds in two main steps. First, we bound the uniform convergence of the tilted empirical risk, and then\nwe show that the TERM algorithm identifies a near-optimal hypothesis over a suitably chosen \u03b5/4-net of C.18\n(i) Uniform Convergence. Noted that the tilted empirical risk for projector-valued functions\neR\u03b3(h) := 1 \u2212 \u00b5c(\u03b3) = 1 \u2212 1\n\u03b3 log\n \n1\nn\nnX",
    "(i) Uniform Convergence. Noted that the tilted empirical risk for projector-valued functions\neR\u03b3(h) := 1 \u2212 \u00b5c(\u03b3) = 1 \u2212 1\n\u03b3 log\n \n1\nn\nnX\ni=1\ne\u03b3Tr[\u03c1i\u03a0(c)\ni ]\n!\n. (58)\nUnder some assumptions (see Theorem 8), it yield that the probability of error is bounded by Theorem 9,\nperr, unif(6T kl) \u2264 8\u03931,\u221e(12T kl, \u03b5/128, C)e\n\u2212 6Tkl\u03b52\n512|e\u03b3\u22121|2 (59)\n(ii) TERM algorithm on \u03b5/2-net of C. Using the classical samples \u20d7 xto construct an \u03b5/2-net C\u03b5/2(\u20d7 x) for C. Apply\nTheorem 7 (ThresholdSearch + Check) to the net of size m = \u03931,\u221e(6T kl, \u03b5/2, C), and output a c\u2217 satisfying\n|\u02c6\u00b5c\u2217(\u03b3) \u2212 max\nc\u2208C(\u20d7 x)\n\u00b5c(\u03b3)| \u22642\u03b5, and |\u02c6\u00b5c\u2217(\u03b3) \u2212 \u00b5c\u2217(\u03b3)| \u22642\u03b5\nsuch that\n\u02c6\u00b5c\u2217(\u03b3) < max\nc\u2208C(\u20d7 x)\n\u00b5c(\u03b3) + 2\u03b5 (60)\nThe probability of error of the TERM is bounded as in the proof of Theorem 7,\nperr, TERM \u2264 T(0.97k + 2(k + 1)e\n\u2212 l|\u03b3|\u03b52\n12(e|\u03b3|\u22121) ) + 4T k\u03931,\u221e(6T kl, \u03b5/2, C)e\n\u2212 l\u03b32\u03b52\n32(e|\u03b3|\u22121)2 , (61)\nby choosing T = O(log 1\n\u03b5 ), k = O(log 1\n\u03b4 log 1\n\u03b5 ) and l so that (log \u03931,\u221e(6T kl, \u03b5/2, C)) + C2)2 \u2264 C1l\u03b52. Thus, for the",
    "\u2212 l|\u03b3|\u03b52\n12(e|\u03b3|\u22121) ) + 4T k\u03931,\u221e(6T kl, \u03b5/2, C)e\n\u2212 l\u03b32\u03b52\n32(e|\u03b3|\u22121)2 , (61)\nby choosing T = O(log 1\n\u03b5 ), k = O(log 1\n\u03b4 log 1\n\u03b5 ) and l so that (log \u03931,\u221e(6T kl, \u03b5/2, C)) + C2)2 \u2264 C1l\u03b52. Thus, for the\nselected concept c\u2217 \u2208 C\u03b5/2(\u20d7 x), we have\n\u00b5c\u2217(\u03b3) \u2264 \u02c6\u00b5c\u2217(\u03b3) + \u03b5\n4 \u2264 inf\nc\u2208C\u03b5/2(\u20d7 x)\n\u02c6\u00b5c(\u03b3) + 2\u03b5 + \u03b5\n4 \u2264 inf\nc\u2208C\n\u02c6\u00b5c(\u03b3) + 2\u03b5 + 3\u03b5\n4 \u2264 inf\nc\u2208C\n\u02c6\u00b5c(\u03b3) + 3\u03b5 (62)\nHence, the probability of error is then upper bounded by both steps, perr, unif + perr, TERM as the desired result.\nIn essence, the subexponential growth of \u0393 1,\u221e(n, \u03b5,C) guarantees that the TERM algorithm identifies a projector-\nvalued hypothesis c\u2217 whose tilted empirical risk is within 3\u03b5 of the best possible among all hypotheses in C. Thus, we\nachieve agnostic learnability of such projector-valued functions under the stated covering number condition.\nVI. QUANTUM TILTED RISK (QTR)\nTilted risk measures extend traditional risk evaluation by incorporating a parameter to control the influence of",
    "VI. QUANTUM TILTED RISK (QTR)\nTilted risk measures extend traditional risk evaluation by incorporating a parameter to control the influence of\nextreme outcomes. In the quantum setting, this concept adapts to the structure of quantum states and observables.\nInspired by classical notions such as the Esscher transform [52, 53] and tilted risk measures, we define the Quantum\nTilted Risk (QTR), which generalizes these concepts to quantum settings (we refer the reader to Ref. [54] for quantum\nnotions on the Esscher transform). The formulation involves a parameterized Hamiltonian H(\u03b8) with an input\nquantum state \u03c1, allowing flexible adjustments via the hyperparameter \u03b3. The example of Hamiltonian learning\n[55\u201358], motivates defining the measure of QTR.\nDefinition 7 (Quantum Tilted Risk (QTR)) . For all \u03b3 \u2208 R, and all \u03d5 \u2208 \u03a6, given an input quantum state \u03c1 and an\nHamiltonian H(\u03d5) parameterized by \u03d5, the \u03b3-tilted QTERM is defined as:\neRQ(\u03b3, \u03d5) := 1\n\u03b3 log Tr\n\u0010\ne\u03b3H(\u03d5)\u03c1\n\u0011\n. (63)",
    "Hamiltonian H(\u03d5) parameterized by \u03d5, the \u03b3-tilted QTERM is defined as:\neRQ(\u03b3, \u03d5) := 1\n\u03b3 log Tr\n\u0010\ne\u03b3H(\u03d5)\u03c1\n\u0011\n. (63)\nIn a learning setting, if \u03c1 represents data encoded in a quantum state and H(\u03d5) represents a hypothesis or model\nparameter \u03d5, then Tr\n\u0000\ne\u03b3H(\u03d5)\u03c1\n\u0001\nmeasures how well the modelH(\u03d5) aligns with the data distribution\u03c1 in an exponential\ntilted scenario. The parameter \u03b3 could be tuned to focus on tail events or rare configurations emphasized by H(\u03d5).19\nA. Properties of QTR\nLemma 11 (Convergence of QTR). The convergence of QTR to the expectation value of Hamiltonian is\nlim\n\u03b3\u21920\neRQ(\u03b3, \u03d5) := eRQ(0, \u03d5) = Tr (H(\u03d5)\u03c1) .\nProof.\nlim\n\u03b3\u21920\neR(\u03b3, \u03d5) = lim\n\u03b3\u21920\n1\n\u03b3 log Tr\n\u0010\ne\u03b3H(\u03d5)\u03c1\n\u0011\n(64)\n(L\u2019H\u02c6 opital\u2019s rule applied to\u03b3) = lim\n\u03b3\u21920\nTr\n\u0000\nH(\u03d5)e\u03b3H(\u03d5)\u03c1\n\u0001\nTr\n\u0000\ne\u03b3H(\u03d5)\u03c1\n\u0001\n= Tr (H(\u03d5)\u03c1) .\nRelation to quantum R\u00b4 enyi relative entropy. The quantum R\u00b4 enyi relative entropy of order \u03b1 > 0 \u0338= 1 is\ndefined as\nD\u03b1(\u03c1\u2225\u03c3) := 1\n\u03b1 \u2212 1 log[Tr(\u03c1\u03b1\u03c31\u2212\u03b1)].",
    "\u0000\nH(\u03d5)e\u03b3H(\u03d5)\u03c1\n\u0001\nTr\n\u0000\ne\u03b3H(\u03d5)\u03c1\n\u0001\n= Tr (H(\u03d5)\u03c1) .\nRelation to quantum R\u00b4 enyi relative entropy. The quantum R\u00b4 enyi relative entropy of order \u03b1 > 0 \u0338= 1 is\ndefined as\nD\u03b1(\u03c1\u2225\u03c3) := 1\n\u03b1 \u2212 1 log[Tr(\u03c1\u03b1\u03c31\u2212\u03b1)].\nAs \u03b1 \u2192 1, it recovers to standard quantum relative entropy. Let \u03c3(\u03d5) be a quantum state parameterized by \u03d5. Define\nH(\u03d5) = log \u03c3(\u03d5) such that\nTr\n\u0010\ne\u03b3 log \u03c3(\u03d5)\u03c1\n\u0011\n= Tr (\u03c3(\u03d5)\u03b3\u03c1) .\neRQ(\u03b3, \u03d5) can be seen as a tilted relative R\u00b4 enyi entropy to measure how\u03c1 and \u03c3(\u03d5) overlap.\nOperational Interpretation. When H(\u03d5) is viewed as a Hamiltonian (i.e., an energy operator) and \u03c1 as a\nquantum state (i.e., a density matrix at fixed temperature), then\nZ\u03d5(\u03b3) := Tr\n\u0010\ne\u03b3H(\u03d5)\u03c1\n\u0011\n.\nresembles a \u201cpartition function\u201d for the state \u03c1 under the energy landscape defined by H(\u03d5). The tilted quantity\neRQ(\u03b3, \u03d5) := 1\n\u03b3 log Tr\n\u0010\ne\u03b3H(\u03d5)\u03c1\n\u0011\n= 1\n\u03b3 log Z\u03d5(\u03b3),\nresembles a quantity of free energy ( F = \u2212kBT ln Z) at the inverse temperature.\nB. On Different Methods of Formulating Tilts",
    "eRQ(\u03b3, \u03d5) := 1\n\u03b3 log Tr\n\u0010\ne\u03b3H(\u03d5)\u03c1\n\u0011\n= 1\n\u03b3 log Z\u03d5(\u03b3),\nresembles a quantity of free energy ( F = \u2212kBT ln Z) at the inverse temperature.\nB. On Different Methods of Formulating Tilts\nThe idea behind implementations of the tilted hyperparameter warrants physical differences among different for-\nmulations. Here we discussed one main definition formalized as QTERM relevant in learning quantum processes.\nWe also briefly motivated the need for tilted measures in other setting such as Hamiltonian learning in a measures\ndenoted as QTR. Below we compare the scenarios where either may be relevant.\n\u2022 QTERM. Specifically tailored for empirical risk minimization in a learning setting. It evaluates the performance\nof quantum hypotheses on given data, with the tilting parameter \u03b3 allowing emphasis on particular outcomes\n(i.e., high-loss scenarios). It is defined over discrete samples and focuses on empirical data.",
    "(i.e., high-loss scenarios). It is defined over discrete samples and focuses on empirical data.\n\u2022 QTR. A generalized risk measure that quantifies the alignment of a parameterized quantum model (Hamiltonian\nH(\u03d5)) with a quantum state \u03c1 and any state learning problem. It is more theoretical and continuous, focusing\non the expected performance in a weighted (tilted) sense.20\nOne of the main differences is found in the data type they are designed to process. In QTERM quantum data is\nrepresented as a set of quantum projectors \u03a0 (c)\ni derived from empirical observations. While in QTR, quantum data\nis encoded in a density operator \u03c1, representing a general quantum state. Furthermore, while QTERM focuses on\nfinite-sample empirical data in a learning framework, QTR is concerned with global system-level evaluations involving\nquantum states and observables. The distinct definitions reflect the different goals: QTERM emphasizes empirical",
    "quantum states and observables. The distinct definitions reflect the different goals: QTERM emphasizes empirical\ndata alignment and hypothesis testing, whereas QTR captures broader properties of quantum systems with a tilt to\nexplore rare or significant states. One can expect other definitions to arise as the scope of quantum machine learning\nbroadens, particularly to address scenarios such as multi-objective optimization in quantum systems, settings where\ndata distributions exhibit extreme variations, or where hybrid quantum-classical models require tailored risk measures.\nFor instance, tilts might be redefined to handle non-Hermitian operators, time-evolved quantum states, or scenarios\nemphasizing specific quantum observables, such as entanglement or coherence. We leave the above as future work\nsuggestions.\nVII. CONCLUDING THOUGHTS AND OPEN DIRECTIONS\nThis work introduces QTERM, a quantum extension of tilted empirical risk minimization that applies a tilt hyper-",
    "suggestions.\nVII. CONCLUDING THOUGHTS AND OPEN DIRECTIONS\nThis work introduces QTERM, a quantum extension of tilted empirical risk minimization that applies a tilt hyper-\nparameter to quantum empirical risk. It unifies and extends classical TERM and QERM, offering a new approach\ntailored to the challenges of quantum data and learning. Inspired by the classical setting, QTERM introduces a tilted\nhyperparameter that penalizes outliers or class imbalances in datasets. A central idea behind this tilt mechanism is\nto help prevent the model from fitting excessively to noisy or anomalous data points, which could lead to overfit-\nting. Further, we have developed theoretical bounds on sample complexity and learning guarantees in the context of\nquantum learning with QTERM. Additionally, we have proved the PAC-type generalization bound for the classical\nTERM. These two findings were used to prove an upper bound on the agnostic learnability of QTERM. Our results",
    "TERM. These two findings were used to prove an upper bound on the agnostic learnability of QTERM. Our results\non quantum process learning provide an understanding of how tilted losses influence the scaling of quantum learning\ntasks with respect to the number of quantum samples. This work contributes to the broader field of quantum learning\nby offering a theoretical understanding for implicitly regularized quantum models, making quantum learning more\npractical and scalable.\nA natural extension of this work would be to expand theoretical proofs to cover larger ranges of the tilt \u03b3. While\nour current analysis focuses on the small- \u03b3 regime to ensure the provable sample complexity bound and learnability,\nunderstanding the theoretical behavior of TERM for large \u03b3 remains an open challenge. Such an extension could\nreveal new insights into the robustness of the method under stronger regularization and its applicability to learning\nscenarios with highly irregular or noisy quantum data.",
    "reveal new insights into the robustness of the method under stronger regularization and its applicability to learning\nscenarios with highly irregular or noisy quantum data.\nFrom the main perspective, QTERM is an advanced quantum loss function that can be practically relevant to\nquantum learning models. While the study of loss functions and quantum regularization has already made efforts\nin understanding certain types of regularizers, i.e., in establishing lower bounds with respect to Lasso and Ridge\nregression [59], and quantum regularized least squares [60, 61] \u2014 there remains ample opportunity to further study\nQTERM, as well as other ways of regularizing. In particular, future research could focus on comparing and establishing\nproperties of QTERM with respect to other types of regularizers such as L2 regularization and L1 regularization, and\nadding regularizers such as entropy to QTERM as well [62], for various quantum learning settings, including quantum",
    "adding regularizers such as entropy to QTERM as well [62], for various quantum learning settings, including quantum\ncircuit learning, quantum neural networks, and quantum reinforcement learning, to determine how QTERM influences\nmodel performance, convergence, and generalization in, for example, noisy quantum environments. Additionally, as a\nfuture work direction, we suggest further generalization bounds which can be derived for QTERM, as a well as other\nproperties such as robustness measures and convergence rates, similar to the methodologies in Ref. [13]. In terms\nof concrete learning model examples, QTERM could be extended to quantum generative models, such as quantum\nGANs or variational autoencoders, and quantum reinforcement learning.\nIn classical optimization, the weighted loss corresponds to the value of the tilt applied to the model\u2019s parameters.\nThis approach is useful in scenarios where different parts of the model need varying levels of emphasis. To address",
    "This approach is useful in scenarios where different parts of the model need varying levels of emphasis. To address\nthis, the classical gradient calculation can be adjusted to incorporate the tilted hyperparameter, allowing the gradient\nto reflect the relative importance of each parameter. In quantum optimization, gradients are similarly required for\nquantum circuits. The definition of QTERM proposed here can be incorporated into existing quantum training\nalgorithms, such as the parameter-shift rule, which is a method for evaluating the gradients of quantum observables\nwith respect to the parameters of quantum circuits [63\u201365]. In training quantum machine learning models, the\nparameter-shift rule addresses the challenges of applying the backpropagation algorithm [66] to these quantum models\n[67]. In context with this work, presence of the tilting hyperparameter motivates us to define tilted parameter shift",
    "[67]. In context with this work, presence of the tilting hyperparameter motivates us to define tilted parameter shift\nrule, which adapts the parameter shift rule to handle weighted losses, offering a more tailored approach to optimization\nin quantum algorithms.\nWith respect to other characterizations and generalization behavior for TERM applied to quantum data, several21\navenues are worth exploring. For instance, margin bounds could be relevant here, as recent work shows that margin-\nbased approaches can provide insightful guarantees about generalization [68\u201370]. In the case of TERM, the value of the\ntilted hyperparameter influences the decision boundary, which can be a motivating point to show how larger margins\nreduce the bound on generalization error. This behavior suggests that the tilted hyperparameter may implicitly\ncontrol the effective margin of the classifier. Larger margins are often associated with tighter generalization bounds,",
    "control the effective margin of the classifier. Larger margins are often associated with tighter generalization bounds,\nproviding a compelling motivation to investigate how varying the tilted hyperparameter could directly influence the\nmargin properties and, consequently, reduce the bound on generalization error. Similarly, stability-based bounds for\ngeneralization error can be a compelling framework [71]. Stability measures the sensitivity of the model to changes\nin the training set, which directly impacts its generalization ability.\nIn summary, in this work we define quantum tilted empirical risk, and in turn extend the classical principle of\nTERM to quantum learning systems, positioning it as a generalization technique. The QTERM framework we propose\nhere, derived from Ref. [31] incorporates a tilted hyperparameter \u03b3 into the loss function. Through this framework,\nwe derived three central theoretical results: a sample complexity guarantee for learning projector-valued functions",
    "we derived three central theoretical results: a sample complexity guarantee for learning projector-valued functions\nunder QTERM, a PAC-style generalization bound for tilted loss minimization in the small- \u03b3 regime, and an agnostic\nlearning guarantee that ensures reliable hypothesis selection even in the absence of a perfect model. Together, these\nresults establish a comprehensive foundation for understanding the statistical and algorithmic properties of learning\nin quantum systems using tilted losses. We believe that QTERM provides a promising direction for future work\nin quantum learning, especially in exploring adaptive strategies for tuning \u03b3 and extending the analysis to broader\nclasses of quantum models.\nAt a broader level, this work highlights the continuing dialogue between classical and quantum perspectives on\nlearning. Classical learning theory has provided a foundation for understanding generalization, regularization, and",
    "learning. Classical learning theory has provided a foundation for understanding generalization, regularization, and\nthe computational limits of artificial systems. Extending these ideas into the quantum domain through QTERM\nreveals how quantum principles reshape long-standing questions of efficiency, robustness, and adaptability in learning.\nIn this sense, QTERM forms part of a larger effort to develop a coherent theory of quantum learning that is both\ncontinuous with and distinct from its classical counterpart. In doing so, the study of quantum learning moves beyond\nalgorithms to touch on deeper questions about the nature of information, computation, and intelligence itself.\nVIII. ACKNOWLEDGMENTS\nWe thank Matthias C. Caro, Vedran Dunjko and Jens Eisert for discussions and feedback. This work is supported\nby the National Research Foundation, Singapore, and A*STAR under its CQT Bridging Grant and its Quantum",
    "by the National Research Foundation, Singapore, and A*STAR under its CQT Bridging Grant and its Quantum\nEngineering Programme under grant NRF2021-QEP2-02-P05. Portions of this manuscript were drafted or edited\nwith the assistance of ChatGPT to improve clarity and style.\nIX. APPENDIX\nA. Lemmas and Propositions\nLemma 12 (Multiplicative Chernoff bound). Let X1, \u00b7\u00b7\u00b7 , Xn be independent random variables taking values in [0, 1].\nDefine X := Pn\ni=1 Xi and let E[X] be the expected value of X. For any 0 \u2264 \u03b5 \u2264 1,\nPr (|X \u2212 E[X]| \u2265n\u03b5) \u2264 2e\u2212E[X]\u03b52/3. (65)\nProposition 13 (Multiplicative Chernoff bound for general bounded variables) . Let X1, \u00b7\u00b7\u00b7 , Xn be independent\nrandom variables taking values in [a, b] that satisfy a, b\u2265 0. Define X := Pn\ni=1 Xi and let E[X] be the expected value\nof X. For any 0 < \u03b4 <1,\nPr(|X \u2212 E[X]| \u2265n\u03b4) \u2264 2e\u2212n\u03b42/[3(b\u2212a)2]. (66)\nProof. When random variables are not restricted to [0 , 1] but instead lie in the positive interval [ a, b], we can reduce",
    "of X. For any 0 < \u03b4 <1,\nPr(|X \u2212 E[X]| \u2265n\u03b4) \u2264 2e\u2212n\u03b42/[3(b\u2212a)2]. (66)\nProof. When random variables are not restricted to [0 , 1] but instead lie in the positive interval [ a, b], we can reduce\nto the case [0 , 1]-by normalization. Let X1, . . . , Xn \u2208 [a, b] be independent random variables. Define:\nYi = Xi \u2212 a\nb \u2212 a , Y :=\nnX\ni=1\nYi22\nso that Yi \u2208 [0, 1] and\n\u00b5Y := E[Y ] = E[X] \u2212 an\nb \u2212 a \u2208 [0, n], with X =\nnX\ni=1\nXi = an + (b \u2212 a)Y.\nBy the standard multiplicative Chernoff bound for Y , for any \u03b5 >0 we have\nP r(Y \u2265 (1 + \u03b5)\u00b5Y ) \u2264 exp\n\u0012\n\u2212\u00b5Y \u03b52\n3\n\u0013\nand similarly for the lower tail. In terms of X, note that\nY \u2265 (1+ \u03b5)\u00b5Y =\u21d2 X \u2265 an+(b\u2212a)(1+ \u03b5)\u00b5Y = \u00b5X(1+ \u03b5)\u2212an\u03b5, Pr(X \u2265 \u00b5X(1+ \u03b5)\u2212an\u03b5) \u2264 exp\n\u0012\n\u2212(\u00b5X \u2212 an)\u03b52\n3(b \u2212 a)\n\u0013\n,\nwhere \u00b5X = E[X]. Similarly, it obtains\nPr(X \u2265 \u00b5X(1 \u2212 \u03b5) + an\u03b5) \u2264 exp\n\u0012\n\u2212(\u00b5X \u2212 an)\u03b52\n2(b \u2212 a)\n\u0013\n.\nCombine the above bounds to obtain\nPr(|X \u2212 \u00b5X| \u2265(\u00b5X \u2212 an)\u03b5) \u2264 2 exp\n\u0012\n\u2212(\u00b5X \u2212 an)\u03b52\n3(b \u2212 a)\n\u0013\n.\nSetting (\u00b5X \u2212 an)\u03b5 = n\u03b4 and using the fact that \u00b5X \u2212 an \u2264 n(b \u2212 a) leads to",
    "\u0012\n\u2212(\u00b5X \u2212 an)\u03b52\n2(b \u2212 a)\n\u0013\n.\nCombine the above bounds to obtain\nPr(|X \u2212 \u00b5X| \u2265(\u00b5X \u2212 an)\u03b5) \u2264 2 exp\n\u0012\n\u2212(\u00b5X \u2212 an)\u03b52\n3(b \u2212 a)\n\u0013\n.\nSetting (\u00b5X \u2212 an)\u03b5 = n\u03b4 and using the fact that \u00b5X \u2212 an \u2264 n(b \u2212 a) leads to\nPr(|X \u2212 \u00b5X| \u2265n\u03b4) \u2264 2 exp\n\u0012\n\u2212 n\u03b42\n3(b \u2212 a)2\n\u0013\nIf a = 0 and b = 1, it recovers the standard multiplicative Chernoff bound.\nLemma 14 (Naive expectation estimation, Proposition 1 in [31]) . The random variable X obtained by measuring the\nobservable \u00af\u03a0 := \u03a01 \u22971 \u2297\u00b7\u00b7\u00b7\u2297 1 + 1 \u2297\u03a02 \u22971 \u00b7\u00b7\u00b7\u2297 1 + 1 \u2297\u00b7\u00b7\u00b7\u2297 1 \u2297\u03a0n on a quantum state \u03c1 = \u03c11 \u2297\u00b7\u00b7\u00b7\u2297 \u03c1n satisfies,\nfor \u03b5 <1,\nP r\n\u0000\f\fX \u2212 E\u03c1[\u00af\u03a0]\n\f\f \u2265 n\u03b5\n\u0001\n\u2264 2e\u2212n\u03b52/3. (67)\nNote that E\u03c1[\u00af\u03a0] = Pn\ns=1 E\u03c1s[\u03a0s] := n(1 \u2212 R(h)) with empirical risk of hypothesis R(h). Based on Lemma 14, we\nextend the concentration result to exponentiated observables, stated next as Proposition 15.\nProposition 15 (Exponential expectation estimation) . Let the random variable {Ys}s\u2208[n] be the measurement out-",
    "Proposition 15 (Exponential expectation estimation) . Let the random variable {Ys}s\u2208[n] be the measurement out-\ncomes by measuring \u00af\u03a0 = {\u03a0s}s\u2208[n] on a collection of a product state \u03c1 components {\u03c1s}s\u2208[n]. Define Xs := ecYs with\na constant c \u2208 R. Since Ys \u2208 [0, 1], each Xs lies in the interval [min{1, ec}, max{1, ec}] and the length of the interval\nof r = |ec \u2212 1|. And define X := Pn\ns=1 Xs = Pn\ns=1 ecYs. Thus, for any 0 \u2264 \u03b5 \u2264 1,\nPr\n\u0000\f\fX \u2212 E\u03c1[X(\u00af\u03a0)]\n\f\f \u2265 n\u03b5\n\u0001\n\u2264 2e\u2212n\u03b52/3r2\n, (68)\nwhere E\u03c1[X(\u00af\u03a0)] = Pn\ns=1 ecE\u03c1s[\u03a0s] represents is the sum of the individual expectation values of the exponentiated\noutcomes.\nProof. The measurement outcomes {Ys}s\u2208[n] are independent scalar random variables. Consequently, {Xs}s\u2208[n] are\nindependent and each is bounded in the interval. By applying multiplicative Chernoff bound in Proposition 13 and\nlet r2 = |1 \u2212 ec|2, one obtains the result in (68).\nLemma 16 (Hoeffding\u2019s Inequality). Let X = x1, \u00b7\u00b7\u00b7 , xN be a finite population of points, each taking values in an",
    "let r2 = |1 \u2212 ec|2, one obtains the result in (68).\nLemma 16 (Hoeffding\u2019s Inequality). Let X = x1, \u00b7\u00b7\u00b7 , xN be a finite population of points, each taking values in an\ninterval [a, b]. Suppose {X1, \u00b7\u00b7\u00b7 , Xn} is a random sample drawn without replacement from X. Let X := Pn\ni=1 Xi and\nlet \u00b5 denote the empirical mean of X. Then for all t >0,\nP r\n \f\f\f\f\f\nnX\ni=1\nXi \u2212 n\u00b5\n\f\f\f\f\f \u2265 nt\n!\n\u2264 2e\u22122nt2/(a\u2212b)2\n.23\nLet us extend Hoeffding\u2019s inequality for sampling without replacement to the case of M different finite populations.\nEach population has N points and we draw n samples without replacement from each population.\nProposition 17 (Hoeffding\u2019s Inequality for Multiple Finite Populations) . Let Y = {1, \u00b7\u00b7\u00b7 , n} and suppose {Xj}l\nj=1\nbe random samples drawn without replacement from Y. Consider M distinct finite populations {X(m)}M\nm=1 with each\nX(m) = {x(m)\nj }n\nj=1 \u2286 [a, b], i.e., maxj x(m)\nj \u2264 b and minj x(m)\nj \u2265 a for all m. Define the population mean of X(m)\nas \u00b5(m) := 1\nl\nPl\nj=1 x(m)",
    "m=1 with each\nX(m) = {x(m)\nj }n\nj=1 \u2286 [a, b], i.e., maxj x(m)\nj \u2264 b and minj x(m)\nj \u2265 a for all m. Define the population mean of X(m)\nas \u00b5(m) := 1\nl\nPl\nj=1 x(m)\nj . From each population X(m), choose a random subset {x(m)\nXi }l\ni=1 and let the sample sum be\nS(m) := Pl\ni=1 x(m)\nXi . Then, for any t >0,\nPr\n\u0012\nmax\nm\u2208[M]\n\f\f\fS(m) \u2212 l\u00b5(m)\n\f\f\f \u2265 lt\n\u0013\n\u2264 2Me\u22122lt2/(b\u2212a)2\n.\nProposition 18 (Hoeffding\u2019s Inequality for Multiple Populations with Batched Sampling) . Let Y = {1, \u00b7\u00b7\u00b7 , n},\nn \u2265 3Kl, and suppose {{Xlk+i}l\ni=1}k=0,\u00b7\u00b7\u00b7,K\u22121 is a random sample drawn without replacement from Y. Consider M\ndistinct finite populations {X(m)}M\nm=1 with each X(m) = {x(m)\nj }n\nj=1 \u2286 [a, b], i.e., maxj x(m)\nj \u2264 b and minj x(m)\nj \u2265 a for\nall m. Define the population mean of X(m) as \u00b5(m) := 1\nl\nPl\nj=1 x(m)\nj . From each population X(m), obtain random K\nsubsets of indices {{x(m)\nXlk+i}l\ni=1}k=0,\u00b7\u00b7\u00b7,K\u22121. Let the sample sum be S(m) := Pl\ni=1 x(m)\nXlk+i. Then, for any t >0,\nPr\n\uf8eb\n\uf8ec\uf8ed max\nm\u2208[M]\nk\u2208{0,\u00b7\u00b7\u00b7,K\u22121}\n\f\f\fS(m) \u2212 l\u00b5(m)",
    "subsets of indices {{x(m)\nXlk+i}l\ni=1}k=0,\u00b7\u00b7\u00b7,K\u22121. Let the sample sum be S(m) := Pl\ni=1 x(m)\nXlk+i. Then, for any t >0,\nPr\n\uf8eb\n\uf8ec\uf8ed max\nm\u2208[M]\nk\u2208{0,\u00b7\u00b7\u00b7,K\u22121}\n\f\f\fS(m) \u2212 l\u00b5(m)\n\f\f\f \u2265 lt\n\uf8f6\n\uf8f7\uf8f8 \u2264 2KMe\n\u2212 2lt2\n4(b\u2212a)2 .\nB. Pseudocode of Algorithms\nIn this appendix, we provide the pseudocode for the main algorithms that form the basis of our QTERM framework,\nfrom Ref. [31].\nAlgorithm 1 Quantum Threshold Search on Nonidentical States ( ThresholdSearch)\nInput: \u03b5, C1, C2 > 0.\nOutput: Of the pairs\nn\u0010\n\u03a0(c)\n1 , . . . ,\u03a0(c)\nn , \u03b8c\n\u0011om\nc=1\n, outputs c\u22c6 \u2208 [m] such that\n1\nn\nnX\ni=1\nTr\nh\n\u03a0(c)\ni \u03c1i\ni\n> \u03b8c\u22c6.\n1: Initialize: \u03c1(0) \u2190 \u03c11 \u2297 . . .\u2297 \u03c1n.\n2: for c = 1, . . . , mdo\n3: Choose: A pair\n\u0010n\n\u03a0(c)\n1 , . . . ,\u03a0(c)\nn\no\n, \u03b8c\n\u0011\n.\n4: Measurement: Apply the two-outcome POVM\n\b\nBc, \u00afBc := 1 \u2212 Bc\n\t\n, where Bc is constructed as in Theorem 8, with\nthreshold \u03b8c \u2212 \u03b5 and with conditions on C1, C2, on \u03c1(c\u22121).\n5: Let \u03c1(c) denote the postmeasurement state.\n6: if the measurement accepts (Bc) then\n7: Return: c.\n8: end if\n9: end for",
    "threshold \u03b8c \u2212 \u03b5 and with conditions on C1, C2, on \u03c1(c\u22121).\n5: Let \u03c1(c) denote the postmeasurement state.\n6: if the measurement accepts (Bc) then\n7: Return: c.\n8: end if\n9: end for\n10: if no measurement is accepted (all hypotheses rejected) then\n11: Return\n12: end if24\nAlgorithm 2 Learning projector-valued functions\nInput: 2T kproduct states {\u03c1s}s\u2208[2Tk] and 2T kmsets of projectors {{h(c)\ns }c\u2208[m]}s\u2208[2Tk], where h(c)\ns = {\u03a0(c)\ns,1, . . . ,\u03a0(c)\ns,l }. Pa-\nrameters: \u03b5, \u03b4, k >0.\n1: Initialize: \u03b8 = 1/2, low = 0, high = 1, failures = 0, s = 0.\n2: while high \u2212 low \u2265 6\u03b5 do\n3: if failures < kthen\n4: s \u2190 s + 1\n5: Threshold Search: Apply Algorithm 1 on the set of projector-threshold pairs\nn\u0010\nh(c)\n2s\u22121, \u03b8\u2212 \u03b5\n\u0011om\nc=1\nwith parameter\n\u03b5/4 to the product state \u03c12s\u22121.\n6: if ThresholdSearch doesn\u2019t output a concept then\n7: failures \u2190 failures +1\n8: else\n9: ThresholdSearch outputs concept c:\n10: Check: Measure h(c)\n2s\u22121 on \u03c12s\u22121 and check if Xc,2s\u22121 \u2265 n(\u03b8 \u2212 7/4\u03b5).\n11: if Check outputs \u2019yes\u2019 then",
    "7: failures \u2190 failures +1\n8: else\n9: ThresholdSearch outputs concept c:\n10: Check: Measure h(c)\n2s\u22121 on \u03c12s\u22121 and check if Xc,2s\u22121 \u2265 n(\u03b8 \u2212 7/4\u03b5).\n11: if Check outputs \u2019yes\u2019 then\n12: low \u2190 \u03b8 \u2212 2\u03b5, high remains unchanged\n13: \u03b8 \u2190 1\n2 (high + low) \u25b7 Update interval to upper half\n14: failures \u2190 0\n15: else\n16: Check outputs \u2019no\u2019\n17: failures \u2190 failures +1\n18: end if\n19: end if\n20: else\n21: k consecutive failures occurred\n22: low remains unchanged, high \u2190 \u03b8\n23: \u03b8 \u2190 1\n2 (high + low) \u25b7 Update interval to lower half\n24: failures\n25: end if\n26: end while\n27: Output: \u03b8 and the last selected concept, if there is one; otherwise, pick one randomly.\n[1] L. Valiant, A theory of the learnable, Communications of the ACM 27, 1134 (1984).\n[2] M. Kearns and U. Vazirani, An Introduction to Computational Learning Theory (MIT Press, 1994).\n[3] M. J. Kearns and R. E. Schapire, Efficient distribution-free learning of probabilistic concepts, Journal of Computer and\nSystem Sciences 48, 464 (1994).",
    "[3] M. J. Kearns and R. E. Schapire, Efficient distribution-free learning of probabilistic concepts, Journal of Computer and\nSystem Sciences 48, 464 (1994).\n[4] C. M. Bishop, Pattern Recognition and Machine Learning (Information Science and Statistics) (Springer-Verlag, Berlin,\nHeidelberg, 2006).\n[5] I. Goodfellow, Y. Bengio, and A. Courville, Deep Learning (MIT Press, 2016) http://www.deeplearningbook.org.\n[6] Y. LeCun, Y. Bengio, and G. Hinton, Deep learning, Nature 521, 436 (2015).\n[7] T. Li, A. Beirami, M. Sanjabi, and V. Smith, Tilted empirical risk minimization, arXiv preprint arXiv:2007.01162 (2020).\n[8] T. Li, A. Beirami, M. Sanjabi, and V. Smith, On tilted losses in machine learning: Theory and applications, Journal of\nMachine Learning Research 24, 1 (2023).\n[9] D. Siegmund, Importance sampling in the monte carlo study of sequential tests, The Annals of Statistics , 673 (1976).",
    "Machine Learning Research 24, 1 (2023).\n[9] D. Siegmund, Importance sampling in the monte carlo study of sequential tests, The Annals of Statistics , 673 (1976).\n[10] R. W. Butler, Saddlepoint approximations with applications , Vol. 22 (Cambridge University Press, 2007).\n[11] M. Thomas and A. T. Joy, Elements of information theory (Wiley-Interscience, 2006).\n[12] A. Dembo, Large deviations techniques and applications (Springer, 2009).\n[13] G. Aminian, A. R. Asadi, T. Li, A. Beirami, G. Reinert, and S. N. Cohen, Generalization error of the tilted empirical risk\n(2024), arXiv:2409.19431 [stat.ML].\n[14] S. L. Smith, B. Dherin, D. G. Barrett, and S. De, On the origin of implicit regularization in stochastic gradient descent,\narXiv preprint arXiv:2101.12176 (2021).\n[15] F. Bauer, S. Pereverzev, and L. Rosasco, On regularization algorithms in learning theory, Journal of Complexity 23, 52\n(2007).",
    "arXiv preprint arXiv:2101.12176 (2021).\n[15] F. Bauer, S. Pereverzev, and L. Rosasco, On regularization algorithms in learning theory, Journal of Complexity 23, 52\n(2007).\n[16] C. D. Mol, E. D. Vito, and L. Rosasco, Elastic-net regularization in learning theory (2008), arXiv:0807.3423 [stat.ML].\n[17] M. Schuld and F. Petruccione, Machine Learning with Quantum Computers , Quantum Science and Technology (Springer\nInternational Publishing, 2021).25\n[18] J. Biamonte, P. Wittek, N. Pancotti, P. Rebentrost, N. Wiebe, and S. Lloyd, Quantum Machine Learning, Nature 549,\n195 (2016).\n[19] P. Rebentrost, M. Mohseni, and S. Lloyd, Quantum support vector machine for big data classification, Physical review\nletters 113, 130503 (2014).\n[20] M. Schuld, A. Bocharov, K. M. Svore, and N. Wiebe, Circuit-centric quantum classifiers, Phys. Rev. A 101, 032308 (2020).\n[21] K. Beer, D. Bondarenko, T. Farrelly, T. J. Osborne, R. Salzmann, D. Scheiermann, and R. Wolf, Training deep quantum",
    "[21] K. Beer, D. Bondarenko, T. Farrelly, T. J. Osborne, R. Salzmann, D. Scheiermann, and R. Wolf, Training deep quantum\nneural networks, Nature communications 11, 808 (2020).\n[22] M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information: 10th Anniversary Edition (Cambridge\nUniversity Press, 2011).\n[23] A. Montanaro, Quantum algorithms: an overview, npj Quantum Information 2, 10.1038/npjqi.2015.23 (2016).\n[24] J. Preskill, Quantum computing in the nisq era and beyond, Quantum 2, 79 (2018).\n[25] P. W. Shor, Fault-tolerant quantum computation, in Proceedings of 37th conference on foundations of computer science\n(IEEE, 1996) pp. 56\u201365.\n[26] M. Cerezo, A. Arrasmith, R. Babbush, S. C. Benjamin, S. Endo, K. Fujii, J. R. McClean, K. Mitarai, X. Yuan, L. Cincio,\nand P. J. Coles, Variational quantum algorithms, Nat. Rev. Phys 3, 625\u2013644 (2021).\n[27] M. Benedetti, E. Lloyd, S. Sack, and M. Fiorentini, Parameterized quantum circuits as machine learning models, Quantum",
    "[27] M. Benedetti, E. Lloyd, S. Sack, and M. Fiorentini, Parameterized quantum circuits as machine learning models, Quantum\nScience and Technology 4, 043001 (2019).\n[28] A. Gily\u00b4 en, Y. Su, G. H. Low, and N. Wiebe, Quantum singular value transformation and beyond: Exponential improvements\nfor quantum matrix arithmetics, in Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing ,\nSTOC 2019 (Association for Computing Machinery, New York, NY, USA, 2019) p. 193\u2013204.\n[29] P. Ivashkov, P.-W. Huang, K. Koor, L. Pira, and P. Rebentrost, Qkan: Quantum kolmogorov-arnold networks (2024),\narXiv:2410.04435 [quant-ph].\n[30] N. Guo, Z. Yu, A. Agrawal, and P. Rebentrost, Quantum linear algebra is all you need for transformer architectures (2024),\narXiv:2402.16714 [quant-ph].\n[31] M. Fanizza, Y. Quek, and M. Rosati, Learning quantum processes without input control, PRX Quantum 5, 020367 (2024).",
    "arXiv:2402.16714 [quant-ph].\n[31] M. Fanizza, Y. Quek, and M. Rosati, Learning quantum processes without input control, PRX Quantum 5, 020367 (2024).\n[32] V. N. Vapnik and A. Y. Chervonenkis, Teoriya raspoznavaniya obrazov [Theory of Pattern Recognition] (Nauka, Moscow,\n1974).\n[33] C. Gyurik, D. Vreumingen, van, and V. Dunjko, Structural risk minimization for quantum linear classifiers, Quantum 7,\n893 (2023).\n[34] M. Heidari, A. Padakandla, and W. Szpankowski, A theoretical framework for learning from quantum data (2021),\narXiv:2107.06406 [quant-ph].\n[35] A. Padakandla and A. Magner, Pac learning of quantum measurement classes: Sample complexity bounds and universal\nconsistency, in International Conference on Artificial Intelligence and Statistics (PMLR, 2022) pp. 11305\u201311319.\n[36] M. Heidari and W. Szpankowski, New bounds on quantum sample complexity of measurement classes, in 2024 IEEE\nInternational Symposium on Information Theory (ISIT) (IEEE, 2024) pp. 1515\u20131520.",
    "[36] M. Heidari and W. Szpankowski, New bounds on quantum sample complexity of measurement classes, in 2024 IEEE\nInternational Symposium on Information Theory (ISIT) (IEEE, 2024) pp. 1515\u20131520.\n[37] C. Ciliberto, A. Rocchetto, A. Rudi, and L. Wossnig, Statistical limits of supervised quantum learning, Physical Review\nA 102, 10.1103/physreva.102.042414 (2020).\n[38] S. Arunachalam and R. De Wolf, Guest column: A survey of quantum learning theory, ACM Sigact News 48, 41 (2017).\n[39] W. Salmon, S. Strelchuk, and T. Gur, Provable advantage in quantum pac learning (2023), arXiv:2309.10887 [quant-ph].\n[40] A. Nayak and P. Sinha, Proper vs improper quantum pac learning (2024), arXiv:2403.03295 [quant-ph].\n[41] K.-M. Chung and H.-H. Lin, Sample Efficient Algorithms for Learning Quantum Channels in PAC Model and the Ap-\nproximate State Discrimination Problem, in 16th Conference on the Theory of Quantum Computation, Communication",
    "proximate State Discrimination Problem, in 16th Conference on the Theory of Quantum Computation, Communication\nand Cryptography (TQC 2021), Leibniz International Proceedings in Informatics (LIPIcs), Vol. 197, edited by M.-H. Hsieh\n(Schloss Dagstuhl \u2013 Leibniz-Zentrum f\u00a8 ur Informatik, Dagstuhl, Germany, 2021) pp. 3:1\u20133:22.\n[42] M. C. Caro, H.-Y. Huang, M. Cerezo, K. Sharma, A. Sornborger, L. Cincio, and P. J. Coles, Generalization in quantum\nmachine learning from few training data, Nature Communications 13, 4919 (2022).\n[43] A. Abbas, D. Sutter, A. Figalli, and S. Woerner, Effective dimension of machine learning models (2021), arXiv:2112.04807\n[cs.LG].\n[44] E. Gil-Fuster, J. Eisert, and C. Bravo-Prieto, Understanding quantum machine learning also requires rethinking general-\nization, Nature Communications 15 (2024).\n[45] N. H. Bshouty and J. C. Jackson, Learning dnf over the uniform distribution using a quantum example oracle, SIAM",
    "ization, Nature Communications 15 (2024).\n[45] N. H. Bshouty and J. C. Jackson, Learning dnf over the uniform distribution using a quantum example oracle, SIAM\nJournal on Computing 28, 1136 (1999), earlier version in COLT\u201995.\n[46] S. Arunachalam and R. de Wolf, Optimal quantum sample complexity of learning algorithms, Journal of Machine Learning\nResearch 19, 1 (2018).\n[47] V. N. Vapnik, Statistical Learning Theory (Wiley-Interscience, 1998).\n[48] M. Anthony and P. L. Bartlett, Neural network learning: Theoretical foundations (Cambridge University Press, 2009).\n[49] C. B\u02d8 adescu and R. O\u2019Donnell, Improved quantum data analysis, TheoretiCSVolume 3, 10.46298/theoretics.24.7 (2024).\n[50] M. M. Wolf, Mathematical foundations of supervised learning (2023).\n[51] M. C. Caro, E. Gil-Fuster, J. J. Meyer, J. Eisert, and R. Sweke, Encoding-dependent generalization bounds for parametrized\nquantum circuits, Quantum 5, 582 (2021).",
    "[51] M. C. Caro, E. Gil-Fuster, J. J. Meyer, J. Eisert, and R. Sweke, Encoding-dependent generalization bounds for parametrized\nquantum circuits, Quantum 5, 582 (2021).\n[52] F. Esscher, On the probability function in the collective theory of risk, Skandinavisk Aktuarietidskrift 15, 175 (1932).\n[53] H. U. Gerber and E. S. W. Shiu, Option pricing by esscher transforms, Transactions of the Society of Actuaries 46, 99\n(1994).\n[54] Y. Qiu, K. Koor, and P. Rebentrost, The quantum esscher transform, arXiv preprint arXiv:2401.07561 (2024).26\n[55] A. Bakshi, A. Liu, A. Moitra, and E. Tang, Learning quantum hamiltonians at any temperature in polynomial time (2023),\narXiv:2310.02243 [quant-ph].\n[56] A. Anshu, S. Arunachalam, T. Kuwahara, and M. Soleimanifar, Sample-efficient learning of interacting quantum systems,\nNature Physics 17, 931\u2013935 (2021).\n[57] A. Gu, L. Cincio, and P. J. Coles, Practical hamiltonian learning with unitary dynamics and gibbs states, Nature Com-",
    "Nature Physics 17, 931\u2013935 (2021).\n[57] A. Gu, L. Cincio, and P. J. Coles, Practical hamiltonian learning with unitary dynamics and gibbs states, Nature Com-\nmunications 15, 312 (2024).\n[58] W. Yu, J. Sun, Z. Han, and X. Yuan, Robust and efficient hamiltonian learning, Quantum 7, 1045 (2023).\n[59] Y. Chen and R. de Wolf, Quantum algorithms and lower bounds for linear regression with norm constraints (2022),\narXiv:2110.13086 [quant-ph].\n[60] Z. Zhu, J. M. Lukens, and B. T. Kirby, On the connection between least squares, regularization, and classical shadows,\nQuantum 8, 1455 (2024).\n[61] S. Chakraborty, A. Morolia, and A. Peduri, Quantum regularized least squares, Quantum 7, 988 (2023).\n[62] G. Aminian, A. R. Asadi, T. Li, A. Beirami, G. Reinert, and S. N. Cohen, Generalization and robustness of the tilted\nempirical risk, in Forty-second International Conference on Machine Learning (2025).",
    "empirical risk, in Forty-second International Conference on Machine Learning (2025).\n[63] K. Mitarai, M. Negoro, M. Kitagawa, and K. Fujii, Quantum circuit learning, Phys. Rev. A 98, 032309 (2018).\n[64] M. Schuld, V. Bergholm, C. Gogolin, J. Izaac, and N. Killoran, Evaluating analytic gradients on quantum hardware,\nPhysical Review A 99, 10.1103/physreva.99.032331 (2019).\n[65] D. Wierichs, J. Izaac, C. Wang, and C. Y.-Y. Lin, General parameter-shift rules for quantum gradients, Quantum 6, 677\n(2022).\n[66] D. E. Rumelhart, G. E. Hinton, and R. J. Williams, Learning representations by back-propagating errors, Nature 323, 533\n(1986).\n[67] A. Abbas, R. King, H.-Y. Huang, W. J. Huggins, R. Movassagh, D. Gilboa, and J. R. McClean, On quantum backpropa-\ngation, information reuse, and cheating measurement collapse (2023), arXiv:2305.13362 [quant-ph].\n[68] T. Hur and D. K. Park, Understanding generalization in quantum machine learning with margins (2024), arXiv:2411.06919\n[quant-ph].",
    "[68] T. Hur and D. K. Park, Understanding generalization in quantum machine learning with margins (2024), arXiv:2411.06919\n[quant-ph].\n[69] B. Neyshabur, S. Bhojanapalli, and N. Srebro, A pac-bayesian approach to spectrally-normalized margin bounds for neural\nnetworks (2018), arXiv:1707.09564 [cs.LG].\n[70] S. Hanneke and A. Kontorovich, Stable sample compression schemes: New applications and an optimal svm margin bound\n(2020), arXiv:2011.04586 [cs.LG].\n[71] O. Bousquet and A. Elisseeff, Stability and generalization, J. Mach. Learn. Res. 2, 499\u2013526 (2002)."
  ],
  "summary": "This document, \"Quantum Learning with Tunable Loss Functions,\" by Yixian Qiu, Lirand\u00eb Pira, and Patrick Rebentrost, introduces a novel theoretical framework called Quantum Tilted Empirical Risk Minimization (QTERM). This framework adapts and extends a classical machine learning technique to the domain of quantum computing, providing a new method for training and regularizing quantum learning models. The paper's primary contributions are the formal definition of QTERM, the derivation of its theoretical learning guarantees, and the establishment of new generalization bounds for its classical counterpart.\n\n### **Background and Motivation**\n\nThe authors begin by situating their work within the broader context of learning theory. At its core, machine learning involves finding a model that best fits a given dataset. This process is guided by a **loss function**, which measures the error between a model's predictions and the actual outcomes. The standard approach, known as **Empirical Risk Minimization (ERM)**, aims to find a model that minimizes the average loss across the entire training dataset.\n\nWhile effective, ERM can be prone to overfitting, where a model learns the training data too well and fails to generalize to new, unseen data. To combat this, techniques like **regularization** are used to penalize model complexity. The paper introduces **Tilted Empirical Risk Minimization (TERM)** as an advanced alternative. TERM extends ERM by incorporating a \"tilting\" hyperparameter into the loss function. This parameter, inspired by the statistical concept of exponential tilting, allows the learning algorithm to selectively emphasize or de-emphasize certain data points. By adjusting this tilt, a model can be trained to be more robust to outliers, handle class imbalances, or achieve better generalization, effectively acting as a form of tunable, implicit regularization.\n\nThe paper then transitions to the quantum domain, where learning from quantum data presents unique challenges. The probabilistic nature of quantum measurements, limitations on distinguishing quantum states, and constraints on accessing information all complicate the direct application of classical learning theories. Existing work has developed a framework for **Quantum Empirical Risk Minimization (QERM)**, but the authors argue for the need for more sophisticated strategies, analogous to TERM, to improve the performance and generalization of quantum models.\n\n### **Introducing Quantum Tilted Empirical Risk Minimization (QTERM)**\n\nThe central contribution of the paper is the formalization of **Quantum Tilted Empirical Risk Minimization (QTERM)**. QTERM is presented as a unification of classical TERM and QERM. It adapts the core idea of TERM\u2014using a tunable parameter to modify the learning objective\u2014to the specifics of learning from quantum data.\n\nIn the QTERM framework, quantum data is processed, and the learning objective is not simply to minimize the average error (as in QERM) but to minimize a *tilted* quantum empirical risk. This is achieved by introducing a tilting hyperparameter that re-weights the contribution of different quantum samples to the overall loss. Operationally, this allows the learning algorithm to focus more on \"harder\" or more informative quantum examples, thereby refining the learning process. The paper provides a precise mathematical formulation for this, where the model (or \"hypothesis\") is represented by a set of quantum measurements (projector-valued functions). The QTERM framework reduces to standard QERM when the tilting parameter is neutral and to classical TERM when applied to classical data.\n\nThe learning process envisioned with QTERM, as illustrated in the paper, involves taking classical data and its quantum state representations as input. An algorithm, such as a \"Quantum Threshold Search,\" then optimizes the choice of a hypothesis to find one that minimizes the tunable tilted loss function. The output is an optimal set of measurements that defines the learned model.\n\n### **Key Theoretical Findings and Contributions**\n\nThe authors establish the theoretical viability and power of QTERM through three main results:\n\n1.  **QTERM Learnability and Sample Complexity:** The paper proves that learning with QTERM is theoretically sound by deriving upper bounds on its **sample complexity**. Sample complexity answers the fundamental question: \"How many data samples are needed to train a model that generalizes well?\" By providing these bounds, the authors demonstrate that QTERM is \"learnable\" within a finite hypothesis space, meaning a model can be trained to a desired level of accuracy with a finite number of quantum examples. This result provides a crucial theoretical foundation for the practical application of QTERM.\n\n2.  **New PAC Generalization Bounds for Classical TERM:** In the process of analyzing QTERM, the authors derive new and improved generalization bounds for classical TERM within the **Probably Approximately Correct (PAC)** learning framework. A PAC bound provides a formal, probabilistic guarantee on a model's performance on unseen data. This finding is a significant contribution to classical learning theory in its own right, showcasing how research into quantum models can yield new insights into their classical analogues.\n\n3.  **Agnostic Learning Guarantees for QTERM:** The paper provides **agnostic learning guarantees** for QTERM. The agnostic setting is a more realistic model of learning where it is not assumed that a perfect hypothesis exists within the set of models being considered. The guarantees show that QTERM can find the best possible hypothesis within its class, even if that hypothesis is not a perfect representation of the underlying reality. This demonstrates the robustness and practical utility of QTERM for real-world problems where data is noisy and perfect models are unattainable.\n\n### **Significance and Conclusion**\n\nThe introduction of QTERM is a significant step forward for the theory of quantum machine learning. It provides a sophisticated and tunable tool for training quantum models, presenting a powerful alternative to traditional explicit and implicit regularization methods. By allowing for the selective emphasis of certain quantum samples, QTERM offers a more nuanced approach to minimizing generalization error and preventing overfitting.\n\nIn conclusion, this work successfully bridges concepts from advanced classical learning theory with the challenges of the quantum domain. By defining QTERM and rigorously proving its learnability, sample complexity, and agnostic learning guarantees, the authors have established a solid theoretical foundation for a new class of quantum learning algorithms. The framework not only enhances the toolkit for quantum machine learning but also contributes new theoretical insights back to the classical field, highlighting the synergistic relationship between the two disciplines.",
  "created_at": "2025-09-01T13:30:42.733041"
}